{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import os\n",
    "import wget\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We have a database (ULL_database) with information about primary and secondary education students in the Canary Islands \n",
    "for 4 academic years. There is information about their academic performance and \n",
    "contextual information (about their families, teachers, and school). The database contains a subset of data \n",
    "in the form of panel data, meaning information about the same students at different points in time (ULL_panel_data).\n",
    "\n",
    "Machine learning algorithms can be used to predict at-risk students. \n",
    "A student is considered at risk if they are anticipated to have low academic performance in the future. \n",
    "Detecting these students would allow for corrective measures to be taken in advance.\n",
    "\n",
    "As a measure of academic performance, we have the variables \"scores\".\n",
    "We have academic performance in Mathematics and in Spanish Language\n",
    "\n",
    "We specify a model to predict at-risk students. Utilizing the panel data,\n",
    "the model aims to forecast whether the student will be at risk in the future (in 6th grade)\n",
    "based on various predictors of current academic performance (3rd grade).\n",
    "\n",
    "Each observation (row) in ULL_panel_data is a student, with their academic performance in sixth grade \n",
    "and their predictors of academic performance from third grade (columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'data/'\n",
    "data = pd.read_csv(os.path.join(DATA, 'ULL_panel_data.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_grade</th>\n",
       "      <th>id_student_16_19</th>\n",
       "      <th>score_MAT</th>\n",
       "      <th>level_MAT</th>\n",
       "      <th>score_LEN</th>\n",
       "      <th>level_LEN</th>\n",
       "      <th>id_student</th>\n",
       "      <th>id_student_original</th>\n",
       "      <th>id_year</th>\n",
       "      <th>id_class_group</th>\n",
       "      <th>...</th>\n",
       "      <th>p331a</th>\n",
       "      <th>p331b</th>\n",
       "      <th>p331c</th>\n",
       "      <th>p331d</th>\n",
       "      <th>p331e</th>\n",
       "      <th>p331f</th>\n",
       "      <th>p331g</th>\n",
       "      <th>p331j</th>\n",
       "      <th>pfc</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>474.9944</td>\n",
       "      <td>2</td>\n",
       "      <td>385.1411</td>\n",
       "      <td>1</td>\n",
       "      <td>20342</td>\n",
       "      <td>1431</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>508.8362</td>\n",
       "      <td>3</td>\n",
       "      <td>469.4856</td>\n",
       "      <td>2</td>\n",
       "      <td>2819</td>\n",
       "      <td>1432</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>590.2816</td>\n",
       "      <td>3</td>\n",
       "      <td>591.1398</td>\n",
       "      <td>3</td>\n",
       "      <td>19276</td>\n",
       "      <td>1436</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>394.4247</td>\n",
       "      <td>1</td>\n",
       "      <td>493.7984</td>\n",
       "      <td>2</td>\n",
       "      <td>14078</td>\n",
       "      <td>1439</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>530.0070</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>1695</td>\n",
       "      <td>1447</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15969</th>\n",
       "      <td>6</td>\n",
       "      <td>17267</td>\n",
       "      <td>599.0310</td>\n",
       "      <td>3</td>\n",
       "      <td>615.6177</td>\n",
       "      <td>4</td>\n",
       "      <td>12265</td>\n",
       "      <td>40236</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>6</td>\n",
       "      <td>17268</td>\n",
       "      <td>538.5835</td>\n",
       "      <td>3</td>\n",
       "      <td>647.9100</td>\n",
       "      <td>4</td>\n",
       "      <td>15982</td>\n",
       "      <td>40238</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>6</td>\n",
       "      <td>17269</td>\n",
       "      <td>537.8327</td>\n",
       "      <td>3</td>\n",
       "      <td>445.1313</td>\n",
       "      <td>2</td>\n",
       "      <td>9965</td>\n",
       "      <td>40240</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>6</td>\n",
       "      <td>17270</td>\n",
       "      <td>468.8731</td>\n",
       "      <td>2</td>\n",
       "      <td>546.8035</td>\n",
       "      <td>3</td>\n",
       "      <td>1137</td>\n",
       "      <td>40246</td>\n",
       "      <td>2016</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>6</td>\n",
       "      <td>17271</td>\n",
       "      <td>440.7426</td>\n",
       "      <td>2</td>\n",
       "      <td>471.8504</td>\n",
       "      <td>2</td>\n",
       "      <td>10732</td>\n",
       "      <td>40247</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15974 rows × 565 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_grade  id_student_16_19  score_MAT  level_MAT  score_LEN  level_LEN  \\\n",
       "0             6                 1   474.9944          2   385.1411          1   \n",
       "1             6                 2   508.8362          3   469.4856          2   \n",
       "2             6                 3   590.2816          3   591.1398          3   \n",
       "3             6                 5   394.4247          1   493.7984          2   \n",
       "4             6                 6   530.0070          3   500.0860          3   \n",
       "...         ...               ...        ...        ...        ...        ...   \n",
       "15969         6             17267   599.0310          3   615.6177          4   \n",
       "15970         6             17268   538.5835          3   647.9100          4   \n",
       "15971         6             17269   537.8327          3   445.1313          2   \n",
       "15972         6             17270   468.8731          2   546.8035          3   \n",
       "15973         6             17271   440.7426          2   471.8504          2   \n",
       "\n",
       "       id_student  id_student_original  id_year id_class_group  ...  p331a  \\\n",
       "0           20342                 1431     2016              A  ...    4.0   \n",
       "1            2819                 1432     2016              A  ...    4.0   \n",
       "2           19276                 1436     2016              A  ...    4.0   \n",
       "3           14078                 1439     2016              A  ...    NaN   \n",
       "4            1695                 1447     2016            NaN  ...    NaN   \n",
       "...           ...                  ...      ...            ...  ...    ...   \n",
       "15969       12265                40236     2016              A  ...    4.0   \n",
       "15970       15982                40238     2016              A  ...    4.0   \n",
       "15971        9965                40240     2016            NaN  ...    NaN   \n",
       "15972        1137                40246     2016              B  ...    3.0   \n",
       "15973       10732                40247     2016            NaN  ...    NaN   \n",
       "\n",
       "       p331b  p331c  p331d  p331e  p331f  p331g  p331j  pfc  rep  \n",
       "0        4.0    4.0    4.0    4.0    3.0    NaN    NaN  NaN  NaN  \n",
       "1        NaN    4.0    4.0    3.0    4.0    NaN    NaN  NaN  NaN  \n",
       "2        4.0    4.0    4.0    2.0    4.0    NaN    NaN  NaN  NaN  \n",
       "3        NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "4        NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  ...  ...  \n",
       "15969    NaN    4.0    4.0    4.0    3.0    NaN    NaN  NaN  NaN  \n",
       "15970    NaN    4.0    4.0    4.0    4.0    NaN    NaN  NaN  NaN  \n",
       "15971    NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "15972    4.0    3.0    3.0    3.0    3.0    NaN    NaN  NaN  NaN  \n",
       "15973    NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "\n",
       "[15974 rows x 565 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the data we want to work for\n",
    "data = data[['id_student_16_19', 'score_MAT', 'score_LEN', 'score_MAT3', 'score_LEN3', 'a1',\n",
    "             'mother_education', 'father_education', 'mother_occupation', 'father_occupation', \n",
    "             'inmigrant_second_gen', 'start_schooling_age', 'books', 'f12a', 'public_private', \n",
    "             'capital_island', 'd14', 'ESCS', 'id_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations with missing data in any of the variables that we will use in the models\n",
    "# Here, synthetic data methods can be used instead to fill in missing values\n",
    "\n",
    "missing_columns = ['score_MAT3', 'a1', 'mother_education', 'father_education',\n",
    "    'mother_occupation', 'father_occupation', 'inmigrant_second_gen',\n",
    "    'start_schooling_age', 'books', 'f12a', 'public_private',\n",
    "    'capital_island', 'd14']\n",
    "\n",
    "data = data.dropna(subset=missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_student_16_19</th>\n",
       "      <th>score_MAT</th>\n",
       "      <th>score_LEN</th>\n",
       "      <th>score_MAT3</th>\n",
       "      <th>score_LEN3</th>\n",
       "      <th>a1</th>\n",
       "      <th>mother_education</th>\n",
       "      <th>father_education</th>\n",
       "      <th>mother_occupation</th>\n",
       "      <th>father_occupation</th>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <th>start_schooling_age</th>\n",
       "      <th>books</th>\n",
       "      <th>f12a</th>\n",
       "      <th>public_private</th>\n",
       "      <th>capital_island</th>\n",
       "      <th>d14</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>id_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>530.0070</td>\n",
       "      <td>500.0860</td>\n",
       "      <td>368.65</td>\n",
       "      <td>339.47</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.132756</td>\n",
       "      <td>2443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>531.9280</td>\n",
       "      <td>459.4065</td>\n",
       "      <td>387.36</td>\n",
       "      <td>566.44</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.069410</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>578.3741</td>\n",
       "      <td>630.4484</td>\n",
       "      <td>549.89</td>\n",
       "      <td>635.53</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.166950</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>481.1748</td>\n",
       "      <td>497.1981</td>\n",
       "      <td>592.00</td>\n",
       "      <td>668.26</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976453</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>521.5593</td>\n",
       "      <td>655.0537</td>\n",
       "      <td>490.28</td>\n",
       "      <td>524.98</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.134441</td>\n",
       "      <td>1859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15968</th>\n",
       "      <td>17266</td>\n",
       "      <td>522.6458</td>\n",
       "      <td>611.0034</td>\n",
       "      <td>574.83</td>\n",
       "      <td>591.86</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.759928</td>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15969</th>\n",
       "      <td>17267</td>\n",
       "      <td>599.0310</td>\n",
       "      <td>615.6177</td>\n",
       "      <td>629.84</td>\n",
       "      <td>460.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.410322</td>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>17268</td>\n",
       "      <td>538.5835</td>\n",
       "      <td>647.9100</td>\n",
       "      <td>600.20</td>\n",
       "      <td>542.78</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>17269</td>\n",
       "      <td>537.8327</td>\n",
       "      <td>445.1313</td>\n",
       "      <td>610.26</td>\n",
       "      <td>600.15</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.382896</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>17270</td>\n",
       "      <td>468.8731</td>\n",
       "      <td>546.8035</td>\n",
       "      <td>709.79</td>\n",
       "      <td>557.48</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.787122</td>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8290 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_student_16_19  score_MAT  score_LEN  score_MAT3  score_LEN3  a1  \\\n",
       "4                     6   530.0070   500.0860      368.65      339.47   1   \n",
       "5                     7   531.9280   459.4065      387.36      566.44   1   \n",
       "7                     9   578.3741   630.4484      549.89      635.53   1   \n",
       "8                    10   481.1748   497.1981      592.00      668.26   2   \n",
       "11                   13   521.5593   655.0537      490.28      524.98   2   \n",
       "...                 ...        ...        ...         ...         ...  ..   \n",
       "15968             17266   522.6458   611.0034      574.83      591.86   1   \n",
       "15969             17267   599.0310   615.6177      629.84      460.75   1   \n",
       "15970             17268   538.5835   647.9100      600.20      542.78   1   \n",
       "15971             17269   537.8327   445.1313      610.26      600.15   2   \n",
       "15972             17270   468.8731   546.8035      709.79      557.48   2   \n",
       "\n",
       "       mother_education  father_education  mother_occupation  \\\n",
       "4                   3.0               1.0                4.0   \n",
       "5                   4.0               4.0                4.0   \n",
       "7                   2.0               2.0                3.0   \n",
       "8                   4.0               4.0                4.0   \n",
       "11                  4.0               4.0                3.0   \n",
       "...                 ...               ...                ...   \n",
       "15968               4.0               3.0                3.0   \n",
       "15969               4.0               3.0                4.0   \n",
       "15970               4.0               2.0                3.0   \n",
       "15971               4.0               1.0                3.0   \n",
       "15972               4.0               2.0                3.0   \n",
       "\n",
       "       father_occupation  inmigrant_second_gen  start_schooling_age  books  \\\n",
       "4                    2.0                   1.0                  1.0    1.0   \n",
       "5                    3.0                   1.0                  1.0    4.0   \n",
       "7                    2.0                   1.0                  2.0    2.0   \n",
       "8                    4.0                   1.0                  1.0    3.0   \n",
       "11                   3.0                   1.0                  1.0    2.0   \n",
       "...                  ...                   ...                  ...    ...   \n",
       "15968                3.0                   1.0                  1.0    4.0   \n",
       "15969                3.0                   1.0                  1.0    4.0   \n",
       "15970                3.0                   1.0                  1.0    2.0   \n",
       "15971                3.0                   1.0                  1.0    3.0   \n",
       "15972                3.0                   1.0                  2.0    4.0   \n",
       "\n",
       "       f12a  public_private  capital_island  d14      ESCS  id_school  \n",
       "4       1.0               2               2  4.0  0.132756       2443  \n",
       "5       5.0               2               1  1.0  1.069410       1368  \n",
       "7       2.0               2               1  1.0 -1.166950       2500  \n",
       "8       4.0               1               1  1.0  0.976453       1610  \n",
       "11      5.0               2               1  1.0 -0.134441       1859  \n",
       "...     ...             ...             ...  ...       ...        ...  \n",
       "15968   2.0               2               1  2.0  0.759928       2413  \n",
       "15969   2.0               2               1  2.0  1.410322       2203  \n",
       "15970   3.0               2               1  2.0  0.035227       2095  \n",
       "15971   2.0               2               1  2.0  0.382896       2097  \n",
       "15972   5.0               2               1  4.0  0.787122       2364  \n",
       "\n",
       "[8290 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.columns \n",
    "data = pd.DataFrame(data.values.flatten().reshape(-1, data.shape[1]), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate quartiles of scores in sixth grade\n",
    "data['score_MATq'] = pd.qcut(data['score_MAT'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['score_MATq'] = data['score_MATq'].astype(int)\n",
    "data['score_LENq'] = pd.qcut(data['score_LEN'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['score_LENq'] = data['score_LENq'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate median and percentiles 25 and 75 of socioeconomic status (ESCS)\n",
    "median_ESCS = data['ESCS'].median()\n",
    "p25_ESCS = data['ESCS'].quantile(0.25)\n",
    "p75_ESCS = data['ESCS'].quantile(0.75)\n",
    "\n",
    "# Initialize with null values\n",
    "data['ESCS_median'] = pd.Series([np.nan] * len(data))\n",
    "data.loc[data['ESCS'] >= median_ESCS, 'ESCS_median'] = 2\n",
    "data.loc[data['ESCS'] < median_ESCS, 'ESCS_median'] = 1\n",
    "data.loc[data['ESCS_median'] == 0, 'ESCS_median'] = np.nan\n",
    "\n",
    "# Initialize with null values\n",
    "data['ESCS_p25_p75'] = pd.Series([np.nan] * len(data))\n",
    "data.loc[data['ESCS'] >= p75_ESCS, 'ESCS_p25_p75'] = 2\n",
    "data.loc[data['ESCS'] < p25_ESCS, 'ESCS_p25_p75'] = 1\n",
    "data.loc[(data['ESCS'] >= p25_ESCS) & (data['ESCS'] < p75_ESCS), 'ESCS_p25_p75'] = np.nan\n",
    "\n",
    "# Some data corrections to make the final results\n",
    "# Variable d14 top category(4) is the \"bad\" category (more than 50% of teachers change school), so the results must be inverted\n",
    "data['d14'] = data['d14'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['score_MAT', 'score_LEN', 'score_MAT3', 'score_LEN3', 'a1',\n",
       "       'mother_education', 'father_education', 'mother_occupation',\n",
       "       'father_occupation', 'inmigrant_second_gen', 'start_schooling_age',\n",
       "       'books', 'f12a', 'public_private', 'capital_island', 'd14', 'ESCS',\n",
       "       'score_MATq', 'score_LENq', 'ESCS_median', 'ESCS_p25_p75'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(\"id_student_16_19\", axis=1)\n",
    "data = data.drop(\"id_school\", axis=1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"MAT\", \"LEN\", \"MAT3\", \"LEN3\"]\n",
    "continuous_scores = [\"score_\" + x for x in subjects]\n",
    "\n",
    "data[continuous_scores] = (data[continuous_scores] - data[continuous_scores].min()) / (data[continuous_scores].max() - data[continuous_scores].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_MAT</th>\n",
       "      <th>score_LEN</th>\n",
       "      <th>score_MAT3</th>\n",
       "      <th>score_LEN3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8290.000000</td>\n",
       "      <td>8290.000000</td>\n",
       "      <td>8290.000000</td>\n",
       "      <td>8290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.496029</td>\n",
       "      <td>0.572530</td>\n",
       "      <td>0.630309</td>\n",
       "      <td>0.674672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.164199</td>\n",
       "      <td>0.154309</td>\n",
       "      <td>0.183068</td>\n",
       "      <td>0.201217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.382484</td>\n",
       "      <td>0.463118</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.521731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.485401</td>\n",
       "      <td>0.574571</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.697501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.604836</td>\n",
       "      <td>0.680854</td>\n",
       "      <td>0.757262</td>\n",
       "      <td>0.832557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score_MAT    score_LEN   score_MAT3   score_LEN3\n",
       "count  8290.000000  8290.000000  8290.000000  8290.000000\n",
       "mean      0.496029     0.572530     0.630309     0.674672\n",
       "std       0.164199     0.154309     0.183068     0.201217\n",
       "min       0.000000     0.000000     0.000000     0.000000\n",
       "25%       0.382484     0.463118     0.497701     0.521731\n",
       "50%       0.485401     0.574571     0.633065     0.697501\n",
       "75%       0.604836     0.680854     0.757262     0.832557\n",
       "max       1.000000     1.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[continuous_scores].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "The goal of the model is to predict the academic performance in sixth grade ($Y_t$)\n",
    "using information from the same student in third grade, specifically:\n",
    "\n",
    "1.  Academic performance in third grade ($Y_{t-1}$)\n",
    "\n",
    "2.  Sensitive factors or circumstances ($C$)\n",
    "\n",
    "3.  Predictors uncorrelated with circumstances, also called \"effort\" ($X$)\n",
    "\n",
    "**Model 1**:    $$Y_t = α + β1Y_{t-1} + ε$$\n",
    "\n",
    "**Model 2**:    $$Y_t = α + β1Y_{t-1} + β2C + ε$$\n",
    "\n",
    "**Model 3**:    \n",
    "\n",
    "> First step: $$Y_{t-1} = α + β2C + ν$$\n",
    "\n",
    "- Recover the prediction of $Y_{t-1}$ (academic performance due to circumstances, $C$): $\\hat{Y}_{t-1}$\n",
    "\n",
    "- Recover the residual $ν$ (academic performance due to effort, $X$): $\\hat{ν}$\n",
    "\n",
    "> Second step: $$Y_t = α + β1\\hat{Y}_{t-1} + β2\\hat{ν} + ε$$\n",
    "\n",
    "- Recover the prediction of $Y_t$ only due to $\\hat{Y}_{t-1}$ (only due to circumstances)\n",
    "\n",
    "- Recover the prediction of $Y_t$ only due to $\\hat{ν}$ (only due to effort)\n",
    "\n",
    "In theory...\n",
    "\n",
    "**Model 1**: Using only the academic performance in third grade (benchmark)\n",
    "\n",
    "**Model 2**: Using the academic performance + circumstances in third grade (less fair - more socially desirable)\n",
    "\n",
    "**Model 3**: Using the circumstances + effort in third grade (close to Model 2)\n",
    "\n",
    "- Prediction exclusively of circumstances of Model 3 (much less fair - much more socially desirable)\n",
    "    \n",
    "- Prediction exclusively of effort of Model 3 (much more fair - much less socially desirable)\n",
    "\n",
    "Let's prove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for the models\n",
    "Y_t_1 = \"score_MAT3\"\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "split = int(len(data) * 0.8)\n",
    "\n",
    "train_data = data.iloc[:split]\n",
    "test_data = data.iloc[split:]\n",
    "\n",
    "train_c = train_data[[\"a1\", \"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \n",
    "      \"inmigrant_second_gen\", \"start_schooling_age\", \"books\", \"f12a\", \"public_private\", \"capital_island\", \"d14\"]]\n",
    "test_c = test_data[[\"a1\", \"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \n",
    "      \"inmigrant_second_gen\", \"start_schooling_age\", \"books\", \"f12a\", \"public_private\", \"capital_island\", \"d14\"]]\n",
    "circumstances = [\"a1\", \"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \n",
    "      \"inmigrant_second_gen\", \"start_schooling_age\", \"books\", \"f12a\", \"public_private\", \"capital_island\", \"d14\"]\n",
    "\n",
    "# Dummy variables (all variables C are categorical variables)\n",
    "train_dummy_variables = pd.get_dummies(train_c, columns=circumstances, drop_first = True)\n",
    "test_dummy_variables = pd.get_dummies(test_c, columns=circumstances, drop_first = True)\n",
    "\n",
    "# Join Y_t_1 + C\n",
    "train_data_combined = pd.concat([train_data[Y_t_1], train_dummy_variables], axis=1)\n",
    "test_data_combined = pd.concat([test_data[Y_t_1], test_dummy_variables], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_MAT</th>\n",
       "      <th>score_LEN</th>\n",
       "      <th>score_MAT3</th>\n",
       "      <th>score_LEN3</th>\n",
       "      <th>a1</th>\n",
       "      <th>mother_education</th>\n",
       "      <th>father_education</th>\n",
       "      <th>mother_occupation</th>\n",
       "      <th>father_occupation</th>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <th>...</th>\n",
       "      <th>books</th>\n",
       "      <th>f12a</th>\n",
       "      <th>public_private</th>\n",
       "      <th>capital_island</th>\n",
       "      <th>d14</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>score_MATq</th>\n",
       "      <th>score_LENq</th>\n",
       "      <th>ESCS_median</th>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>0.765039</td>\n",
       "      <td>0.657338</td>\n",
       "      <td>0.738193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.191348</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>0.462080</td>\n",
       "      <td>0.636803</td>\n",
       "      <td>0.938956</td>\n",
       "      <td>0.782606</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536982</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>0.403198</td>\n",
       "      <td>0.369274</td>\n",
       "      <td>0.705725</td>\n",
       "      <td>0.355770</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.708335</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>0.365334</td>\n",
       "      <td>0.469595</td>\n",
       "      <td>0.526876</td>\n",
       "      <td>0.714836</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382896</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>0.394645</td>\n",
       "      <td>0.443683</td>\n",
       "      <td>0.462825</td>\n",
       "      <td>0.590729</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.627731</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8285</th>\n",
       "      <td>0.687545</td>\n",
       "      <td>0.937725</td>\n",
       "      <td>0.693894</td>\n",
       "      <td>0.705915</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.947430</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8286</th>\n",
       "      <td>0.360611</td>\n",
       "      <td>0.733824</td>\n",
       "      <td>0.880918</td>\n",
       "      <td>0.681435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536982</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8287</th>\n",
       "      <td>0.688505</td>\n",
       "      <td>0.760862</td>\n",
       "      <td>0.575893</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.502406</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8288</th>\n",
       "      <td>0.675909</td>\n",
       "      <td>0.412674</td>\n",
       "      <td>0.421985</td>\n",
       "      <td>0.618252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.289729</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8289</th>\n",
       "      <td>0.242507</td>\n",
       "      <td>0.354868</td>\n",
       "      <td>0.540202</td>\n",
       "      <td>0.481398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.415054</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1658 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score_MAT  score_LEN  score_MAT3  score_LEN3   a1  mother_education  \\\n",
       "6632   0.765039   0.657338    0.738193    1.000000  1.0               4.0   \n",
       "6633   0.462080   0.636803    0.938956    0.782606  2.0               3.0   \n",
       "6634   0.403198   0.369274    0.705725    0.355770  2.0               2.0   \n",
       "6635   0.365334   0.469595    0.526876    0.714836  2.0               2.0   \n",
       "6636   0.394645   0.443683    0.462825    0.590729  2.0               1.0   \n",
       "...         ...        ...         ...         ...  ...               ...   \n",
       "8285   0.687545   0.937725    0.693894    0.705915  2.0               4.0   \n",
       "8286   0.360611   0.733824    0.880918    0.681435  2.0               3.0   \n",
       "8287   0.688505   0.760862    0.575893    0.804020  2.0               3.0   \n",
       "8288   0.675909   0.412674    0.421985    0.618252  1.0               4.0   \n",
       "8289   0.242507   0.354868    0.540202    0.481398  1.0               2.0   \n",
       "\n",
       "      father_education  mother_occupation  father_occupation  \\\n",
       "6632               3.0                3.0                3.0   \n",
       "6633               2.0                3.0                4.0   \n",
       "6634               4.0                2.0                2.0   \n",
       "6635               4.0                3.0                3.0   \n",
       "6636               2.0                1.0                3.0   \n",
       "...                ...                ...                ...   \n",
       "8285               4.0                4.0                4.0   \n",
       "8286               4.0                4.0                4.0   \n",
       "8287               4.0                3.0                3.0   \n",
       "8288               3.0                3.0                3.0   \n",
       "8289               1.0                3.0                3.0   \n",
       "\n",
       "      inmigrant_second_gen  ...  books  f12a  public_private  capital_island  \\\n",
       "6632                   1.0  ...    4.0   5.0             2.0             1.0   \n",
       "6633                   1.0  ...    2.0   5.0             2.0             1.0   \n",
       "6634                   1.0  ...    1.0   1.0             1.0             1.0   \n",
       "6635                   1.0  ...    3.0   2.0             2.0             1.0   \n",
       "6636                   1.0  ...    1.0   1.0             2.0             1.0   \n",
       "...                    ...  ...    ...   ...             ...             ...   \n",
       "8285                   1.0  ...    3.0   5.0             1.0             1.0   \n",
       "8286                   1.0  ...    2.0   5.0             1.0             1.0   \n",
       "8287                   1.0  ...    4.0   4.0             2.0             1.0   \n",
       "8288                   1.0  ...    2.0   2.0             1.0             1.0   \n",
       "8289                   1.0  ...    4.0   5.0             2.0             2.0   \n",
       "\n",
       "      d14      ESCS  score_MATq  score_LENq  ESCS_median  ESCS_p25_p75  \n",
       "6632    0  1.191348           4           3          2.0           2.0  \n",
       "6633    0  0.536982           2           3          2.0           NaN  \n",
       "6634    0 -0.708335           2           1          1.0           1.0  \n",
       "6635    0  0.382896           1           2          2.0           NaN  \n",
       "6636    0 -1.627731           2           1          1.0           1.0  \n",
       "...   ...       ...         ...         ...          ...           ...  \n",
       "8285    1  1.947430           4           4          2.0           2.0  \n",
       "8286    1  0.536982           1           4          2.0           NaN  \n",
       "8287    1  1.502406           4           4          2.0           2.0  \n",
       "8288    1  0.289729           4           1          2.0           NaN  \n",
       "8289    0 -0.415054           1           1          1.0           NaN  \n",
       "\n",
       "[1658 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1658, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/99475333.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'model1_pred'] = model1.predict(sm.add_constant(test_data[Y_t_1]))\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "model1 = sm.OLS(train_data[\"score_MAT\"], sm.add_constant(train_data[Y_t_1])).fit()\n",
    "model1.summary()\n",
    "test_data.loc[:, 'model1_pred'] = model1.predict(sm.add_constant(test_data[Y_t_1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "# model1 = sm.OLS(data[\"score_MAT\"], sm.add_constant(data[Y_t_1])).fit()\n",
    "# print(model1.summary())\n",
    "# data['model1_pred'] = model1.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "# model2 = sm.OLS(data[\"score_MAT\"], sm.add_constant(data_combined.astype(np.float64))).fit()\n",
    "# print(model2.summary())\n",
    "# data['model2_pred'] = model2.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              score_MAT   R-squared:                       0.270\n",
      "Model:                            OLS   Adj. R-squared:                  0.267\n",
      "Method:                 Least Squares   F-statistic:                     90.43\n",
      "Date:                Thu, 19 Sep 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:54:29   Log-Likelihood:                 3608.5\n",
      "No. Observations:                6632   AIC:                            -7161.\n",
      "Df Residuals:                    6604   BIC:                            -6971.\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        0.1775      0.031      5.772      0.000       0.117       0.238\n",
      "score_MAT3                   0.4165      0.010     42.063      0.000       0.397       0.436\n",
      "a1_2.0                      -0.0060      0.003     -1.723      0.085      -0.013       0.001\n",
      "mother_education_2.0        -0.0009      0.007     -0.123      0.902      -0.015       0.013\n",
      "mother_education_3.0         0.0092      0.007      1.234      0.217      -0.005       0.024\n",
      "mother_education_4.0         0.0123      0.008      1.629      0.103      -0.003       0.027\n",
      "father_education_2.0         0.0079      0.006      1.348      0.178      -0.004       0.019\n",
      "father_education_3.0         0.0120      0.006      1.973      0.049    7.79e-05       0.024\n",
      "father_education_4.0         0.0333      0.006      5.207      0.000       0.021       0.046\n",
      "mother_occupation_2.0       -0.0002      0.014     -0.014      0.989      -0.027       0.027\n",
      "mother_occupation_3.0       -0.0023      0.013     -0.170      0.865      -0.029       0.024\n",
      "mother_occupation_4.0       -0.0018      0.014     -0.127      0.899      -0.029       0.025\n",
      "father_occupation_2.0        0.0171      0.029      0.596      0.552      -0.039       0.073\n",
      "father_occupation_3.0        0.0206      0.028      0.726      0.468      -0.035       0.076\n",
      "father_occupation_4.0        0.0234      0.029      0.819      0.413      -0.033       0.079\n",
      "inmigrant_second_gen_2.0     0.0038      0.007      0.537      0.591      -0.010       0.018\n",
      "start_schooling_age_2.0     -0.0033      0.004     -0.846      0.397      -0.011       0.004\n",
      "start_schooling_age_3.0     -0.0183      0.013     -1.443      0.149      -0.043       0.007\n",
      "books_2.0                    0.0140      0.006      2.417      0.016       0.003       0.025\n",
      "books_3.0                    0.0228      0.007      3.515      0.000       0.010       0.036\n",
      "books_4.0                    0.0344      0.007      4.884      0.000       0.021       0.048\n",
      "f12a_2.0                    -0.0024      0.008     -0.301      0.764      -0.018       0.013\n",
      "f12a_3.0                    -0.0048      0.012     -0.390      0.696      -0.029       0.019\n",
      "f12a_4.0                    -0.0031      0.009     -0.361      0.718      -0.020       0.014\n",
      "f12a_5.0                    -0.0074      0.008     -0.901      0.368      -0.023       0.009\n",
      "public_private_2.0           0.0030      0.005      0.601      0.548      -0.007       0.013\n",
      "capital_island_2.0           0.0052      0.005      1.017      0.309      -0.005       0.015\n",
      "d14_1                       -0.0026      0.004     -0.601      0.548      -0.011       0.006\n",
      "==============================================================================\n",
      "Omnibus:                       25.582   Durbin-Watson:                   1.984\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.721\n",
      "Skew:                           0.128   Prob(JB):                     1.58e-06\n",
      "Kurtosis:                       3.176   Cond. No.                         69.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/3183405957.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'model2_pred'] = model2.predict(sm.add_constant(test_data_combined.astype(np.float64)))\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "model2 = sm.OLS(train_data[\"score_MAT\"], sm.add_constant(train_data_combined.astype(np.float64))).fit()\n",
    "print(model2.summary())\n",
    "test_data.loc[:, 'model2_pred'] = model2.predict(sm.add_constant(test_data_combined.astype(np.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "# model3 = sm.OLS(data[\"score_MAT3\"], sm.add_constant(dummy_variables.astype(np.float64))).fit()\n",
    "# print(model3.summary())\n",
    "\n",
    "# First step\n",
    "# data['Y_t_1_hat'] = model3.fittedvalues\n",
    "# data['ν_hat'] = model3.resid\n",
    "\n",
    "# Second step\n",
    "# model4 = sm.OLS(data[\"score_MAT\"], sm.add_constant(data[[\"Y_t_1_hat\", \"ν_hat\"]])).fit()\n",
    "# print(model4.summary())\n",
    "# data['model3_pred'] = model4.fittedvalues\n",
    "\n",
    "# Prediction exclusively of circumstances\n",
    "# data['model3_pred_circum'] = model4.params['const'] + model4.params['Y_t_1_hat'] * data['Y_t_1_hat']\n",
    "# Prediction exclusively of effort\n",
    "# mean_circu = data['Y_t_1_hat'].mean()\n",
    "# data['mean_circu'] = mean_circu\n",
    "# data['model3_pred_effort'] = (model4.params['const'] + \n",
    "                          # model4.params['ν_hat'] * data['ν_hat'] + \n",
    "                          # model4.params['Y_t_1_hat'] * mean_circu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             score_MAT3   R-squared:                       0.094\n",
      "Model:                            OLS   Adj. R-squared:                  0.091\n",
      "Method:                 Least Squares   F-statistic:                     26.45\n",
      "Date:                Thu, 19 Sep 2024   Prob (F-statistic):          1.69e-121\n",
      "Time:                        14:54:29   Log-Likelihood:                 2167.9\n",
      "No. Observations:                6632   AIC:                            -4282.\n",
      "Df Residuals:                    6605   BIC:                            -4098.\n",
      "Df Model:                          26                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        0.4875      0.038     12.920      0.000       0.413       0.561\n",
      "a1_2.0                      -0.0134      0.004     -3.120      0.002      -0.022      -0.005\n",
      "mother_education_2.0         0.0135      0.009      1.494      0.135      -0.004       0.031\n",
      "mother_education_3.0         0.0338      0.009      3.657      0.000       0.016       0.052\n",
      "mother_education_4.0         0.0582      0.009      6.202      0.000       0.040       0.077\n",
      "father_education_2.0         0.0209      0.007      2.870      0.004       0.007       0.035\n",
      "father_education_3.0         0.0341      0.008      4.524      0.000       0.019       0.049\n",
      "father_education_4.0         0.0561      0.008      7.090      0.000       0.041       0.072\n",
      "mother_occupation_2.0        0.0446      0.017      2.584      0.010       0.011       0.079\n",
      "mother_occupation_3.0        0.0418      0.017      2.508      0.012       0.009       0.075\n",
      "mother_occupation_4.0        0.0494      0.017      2.871      0.004       0.016       0.083\n",
      "father_occupation_2.0       -0.0214      0.036     -0.600      0.548      -0.091       0.048\n",
      "father_occupation_3.0       -0.0115      0.035     -0.327      0.744      -0.081       0.058\n",
      "father_occupation_4.0       -0.0111      0.036     -0.313      0.754      -0.081       0.059\n",
      "inmigrant_second_gen_2.0    -0.0075      0.009     -0.853      0.393      -0.025       0.010\n",
      "start_schooling_age_2.0     -0.0085      0.005     -1.753      0.080      -0.018       0.001\n",
      "start_schooling_age_3.0     -0.0102      0.016     -0.647      0.518      -0.041       0.021\n",
      "books_2.0                    0.0227      0.007      3.156      0.002       0.009       0.037\n",
      "books_3.0                    0.0475      0.008      5.898      0.000       0.032       0.063\n",
      "books_4.0                    0.0657      0.009      7.547      0.000       0.049       0.083\n",
      "f12a_2.0                     0.0082      0.010      0.825      0.410      -0.011       0.028\n",
      "f12a_3.0                     0.0304      0.015      1.981      0.048       0.000       0.060\n",
      "f12a_4.0                     0.0152      0.011      1.413      0.158      -0.006       0.036\n",
      "f12a_5.0                     0.0010      0.010      0.098      0.922      -0.019       0.021\n",
      "public_private_2.0           0.0080      0.006      1.303      0.193      -0.004       0.020\n",
      "capital_island_2.0          -0.0304      0.006     -4.770      0.000      -0.043      -0.018\n",
      "d14_1                        0.0227      0.005      4.188      0.000       0.012       0.033\n",
      "==============================================================================\n",
      "Omnibus:                       95.355   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               56.704\n",
      "Skew:                           0.029   Prob(JB):                     4.86e-13\n",
      "Kurtosis:                       2.551   Cond. No.                         65.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              score_MAT   R-squared:                       0.265\n",
      "Model:                            OLS   Adj. R-squared:                  0.265\n",
      "Method:                 Least Squares   F-statistic:                     1196.\n",
      "Date:                Thu, 19 Sep 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:54:29   Log-Likelihood:                 3587.0\n",
      "No. Observations:                6632   AIC:                            -7168.\n",
      "Df Residuals:                    6629   BIC:                            -7148.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0102      0.019      0.523      0.601      -0.028       0.048\n",
      "Y_t_1_hat      0.7699      0.031     25.049      0.000       0.710       0.830\n",
      "ν_hat          0.4165      0.010     42.006      0.000       0.397       0.436\n",
      "==============================================================================\n",
      "Omnibus:                       25.459   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.816\n",
      "Skew:                           0.125   Prob(JB):                     1.50e-06\n",
      "Kurtosis:                       3.187   Cond. No.                         24.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.loc[:, 'Y_t_1_hat'] = model3.fittedvalues\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.loc[:, 'ν_hat'] = model3.resid\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'Y_t_1_hat'] = model3.predict(sm.add_constant(test_dummy_variables.astype(np.float64)))\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'ν_hat'] = test_data[\"score_MAT3\"] - test_data.loc[:, 'Y_t_1_hat']\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'model3_pred'] = model4.predict(sm.add_constant(pd.concat([test_data[\"Y_t_1_hat\"], test_data[\"ν_hat\"]], axis = 1)))\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'model3_pred_circum'] = model4.params['const'] + model4.params['Y_t_1_hat'] * test_data['Y_t_1_hat']\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'mean_circu'] = mean_circu\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1741112637.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'model3_pred_effort'] = (model4.params['const'] +\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "model3 = sm.OLS(train_data[\"score_MAT3\"], sm.add_constant(train_dummy_variables.astype(np.float64))).fit()\n",
    "print(model3.summary())\n",
    "\n",
    "# First step\n",
    "train_data.loc[:, 'Y_t_1_hat'] = model3.fittedvalues\n",
    "train_data.loc[:, 'ν_hat'] = model3.resid\n",
    "\n",
    "# Second step\n",
    "model4 = sm.OLS(train_data[\"score_MAT\"], sm.add_constant(pd.concat([train_data[\"Y_t_1_hat\"], train_data[\"ν_hat\"]], axis = 1))).fit()\n",
    "print(model4.summary())\n",
    "\n",
    "test_data.loc[:, 'Y_t_1_hat'] = model3.predict(sm.add_constant(test_dummy_variables.astype(np.float64)))\n",
    "test_data.loc[:, 'ν_hat'] = test_data[\"score_MAT3\"] - test_data.loc[:, 'Y_t_1_hat']\n",
    "\n",
    "test_data.loc[:, 'model3_pred'] = model4.predict(sm.add_constant(pd.concat([test_data[\"Y_t_1_hat\"], test_data[\"ν_hat\"]], axis = 1)))\n",
    "\n",
    "# Prediction exclusively of circumstances\n",
    "test_data.loc[:, 'model3_pred_circum'] = model4.params['const'] + model4.params['Y_t_1_hat'] * test_data['Y_t_1_hat']\n",
    "# Prediction exclusively of effort\n",
    "mean_circu = test_data.loc[:, 'Y_t_1_hat'].mean()\n",
    "test_data.loc[:, 'mean_circu'] = mean_circu\n",
    "test_data.loc[:, 'model3_pred_effort'] = (model4.params['const'] + \n",
    "                          model4.params['ν_hat'] * test_data['ν_hat'] + \n",
    "                          model4.params['Y_t_1_hat'] * mean_circu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_discrete'] = pd.qcut(data['score_MAT'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4 2 2 ... 4 4 1]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, 'score_MAT_discrete'] = data['score_MAT_discrete'].astype(int)\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred1'] = pd.qcut(data['model1_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[3 4 3 ... 2 1 2]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, 'score_MAT_pred1'] = data['score_MAT_pred1'].astype(int)\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred2'] = pd.qcut(data['model2_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4 4 3 ... 3 1 2]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, 'score_MAT_pred2'] = data['score_MAT_pred2'].astype(int)\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred3'] = pd.qcut(data['model3_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4 4 3 ... 3 1 2]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, 'score_MAT_pred3'] = data['score_MAT_pred3'].astype(int)\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred_C'] = pd.qcut(data['model3_pred_circum'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4 1 1 ... 4 3 1]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, 'score_MAT_pred_C'] = data['score_MAT_pred_C'].astype(int)\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred_X'] = pd.qcut(data['model3_pred_effort'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[3 4 4 ... 2 1 2]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, 'score_MAT_pred_X'] = data['score_MAT_pred_X'].astype(int)\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred1_t'] = data['score_MAT_pred1'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred2_t'] = data['score_MAT_pred2'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred3_t'] = data['score_MAT_pred3'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred_C_t'] = data['score_MAT_pred_C'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/1188819918.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'score_MAT_pred_X_t'] = data['score_MAT_pred_X'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n"
     ]
    }
   ],
   "source": [
    "# Transform predictions(continuous) to quartiles(categorical)\n",
    "\n",
    "def discretise_scores(data):\n",
    "    data.loc[:, 'score_MAT_discrete'] = pd.qcut(data['score_MAT'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "    data.loc[:, 'score_MAT_discrete'] = data['score_MAT_discrete'].astype(int)\n",
    "\n",
    "    data.loc[:, 'score_MAT_pred1'] = pd.qcut(data['model1_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "    data.loc[:, 'score_MAT_pred1'] = data['score_MAT_pred1'].astype(int)\n",
    "    data.loc[:, 'score_MAT_pred2'] = pd.qcut(data['model2_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "    data.loc[:, 'score_MAT_pred2'] = data['score_MAT_pred2'].astype(int)\n",
    "    data.loc[:, 'score_MAT_pred3'] = pd.qcut(data['model3_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "    data.loc[:, 'score_MAT_pred3'] = data['score_MAT_pred3'].astype(int)\n",
    "    data.loc[:, 'score_MAT_pred_C'] = pd.qcut(data['model3_pred_circum'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "    data.loc[:, 'score_MAT_pred_C'] = data['score_MAT_pred_C'].astype(int)\n",
    "    data.loc[:, 'score_MAT_pred_X'] = pd.qcut(data['model3_pred_effort'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "    data.loc[:, 'score_MAT_pred_X'] = data['score_MAT_pred_X'].astype(int)\n",
    "\n",
    "    # Transform predictions(continuous) to percentiles but percentiles 2 and 3 equal (between 25th and 75th percentile)\n",
    "\n",
    "    data.loc[:, 'score_MAT_pred1_t'] = data['score_MAT_pred1'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "    data.loc[:, 'score_MAT_pred2_t'] = data['score_MAT_pred2'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "    data.loc[:, 'score_MAT_pred3_t'] = data['score_MAT_pred3'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "    data.loc[:, 'score_MAT_pred_C_t'] = data['score_MAT_pred_C'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "    data.loc[:, 'score_MAT_pred_X_t'] = data['score_MAT_pred_X'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "\n",
    "    return data\n",
    "\n",
    "test_data = discretise_scores(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on **Equalized Odds** (Equality of opportunity).\n",
    "\n",
    "To calculate Equalized Odds we first calculate recall or sensitivity:\n",
    "\n",
    "$$TP / (TP + FN)$$\n",
    "\n",
    "and then we calculate the ratio of recall among different groups to obtain Equalized Odds.\n",
    "\n",
    "Recall is calculated for Low and High academic performance:\n",
    "- **Low academic performance**: Below the median or 25th percentile\n",
    "- **High academic performance**: Above the median or above 75th percentile (top 25 percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(data):\n",
    "\n",
    "    recall_dfs_25_75 = []\n",
    "    recall_dfs_25_75.extend(compute_recall(data, [\"f12a\"], top_level=5))\n",
    "    recall_dfs_25_75.extend(compute_recall(data, [\"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \"books\"], top_level=4))\n",
    "    recall_dfs_25_75.extend(compute_recall(data, [\"start_schooling_age\"], top_level=1))\n",
    "    recall_dfs_25_75.extend(compute_recall(data, [\"inmigrant_second_gen\", \"public_private\", \"capital_island\", \"a1\", \"ESCS_median\", \"ESCS_p25_p75\", \"d14\"], top_level=1))\n",
    "\n",
    "    recall_dfs_between25_75 = []\n",
    "    recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"f12a\"], top_level=5))\n",
    "    recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \"books\"], top_level=4))\n",
    "    recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"start_schooling_age\"], top_level=1))\n",
    "    recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"inmigrant_second_gen\", \"public_private\", \"capital_island\", \"a1\", \"ESCS_median\", \"ESCS_p25_p75\", \"d14\"], top_level=1))\n",
    "\n",
    "    recall_dfs_median = []\n",
    "    recall_dfs_median.extend(compute_recall_median(data, [\"f12a\"], top_level=5))\n",
    "    recall_dfs_median.extend(compute_recall_median(data, [\"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \"books\"], top_level=4))\n",
    "    recall_dfs_median.extend(compute_recall_median(data, [\"start_schooling_age\"], top_level=1))\n",
    "    recall_dfs_median.extend(compute_recall_median(data, [\"inmigrant_second_gen\", \"public_private\", \"capital_island\", \"a1\", \"ESCS_median\", \"ESCS_p25_p75\", \"d14\"], top_level=1))\n",
    "\n",
    "    # Combine DataFrames\n",
    "    combined_df_25_75 = pd.concat(recall_dfs_25_75, ignore_index=True)\n",
    "    combined_df_between25_75 = pd.concat(recall_dfs_between25_75, ignore_index=True)\n",
    "    combined_df_median = pd.concat(recall_dfs_median, ignore_index=True)\n",
    "\n",
    "    return combined_df_25_75, combined_df_between25_75, combined_df_median\n",
    "\n",
    "combined_df_25_75, combined_df_between25_75, combined_df_median = compute_results(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tables\n",
    "pivot_combined_df_25_75 = combined_df_25_75.pivot_table(index=['Variable', 'Group', 'Percentile'], columns='Model', values='Recall').reset_index()\n",
    "pivot_combined_df_25_75 = pivot_combined_df_25_75[['Variable', 'Group', 'Percentile', 'pred1', 'pred2', 'pred3', 'pred_C', 'pred_X']]\n",
    "pivot_combined_df_25_75_sorted = pivot_combined_df_25_75.sort_values(by=['Percentile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "pivot_combined_df_between25_75 = combined_df_between25_75.pivot_table(index=['Variable', 'Group', 'Tercile'], columns='Model', values='Recall').reset_index()\n",
    "pivot_combined_df_between25_75 = pivot_combined_df_between25_75[['Variable', 'Group', 'Tercile', 'pred1_t', 'pred2_t', 'pred3_t', 'pred_C_t', 'pred_X_t']]\n",
    "pivot_combined_df_between25_75_sorted = pivot_combined_df_between25_75.sort_values(by=['Tercile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "pivot_combined_df_median = combined_df_median.pivot_table(index=['Variable', 'Group', 'Pair1', 'Pair2'], columns='Model', values='Recall').reset_index()\n",
    "pivot_combined_df_median = pivot_combined_df_median[['Variable', 'Group', 'Pair1', 'Pair2', 'pred1', 'pred2', 'pred3', 'pred_C', 'pred_X']]\n",
    "pivot_combined_df_median_sorted = pivot_combined_df_median.sort_values(by=['Pair1', 'Pair2', 'Variable', 'Group'], ascending=[True, True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_25_75 = []\n",
    "\n",
    "for variable in pivot_combined_df_25_75_sorted['Variable'].unique():\n",
    "    variable_df = pivot_combined_df_25_75_sorted[pivot_combined_df_25_75_sorted['Variable'] == variable]\n",
    "    for percentile in variable_df['Percentile'].unique():\n",
    "        top_row = variable_df[(variable_df['Group'] == 'top') & (variable_df['Percentile'] == percentile)]\n",
    "        if not top_row.empty:\n",
    "            top_row = top_row.iloc[0]\n",
    "            temp_data = []\n",
    "            for _, row in variable_df[variable_df['Percentile'] == percentile].iterrows():\n",
    "                odds_row = {\n",
    "                    'Variable': row['Variable'],\n",
    "                    'Group': row['Group'],\n",
    "                    'Percentile': row['Percentile'],\n",
    "                    'pred1': row['pred1'],\n",
    "                    'pred2': row['pred2'],\n",
    "                    'pred3': row['pred3'],\n",
    "                    'pred_C': row['pred_C'],\n",
    "                    'pred_X': row['pred_X'],\n",
    "                    'pred1_odds': calculate_odds(row['pred1'], top_row['pred1']),\n",
    "                    'pred2_odds': calculate_odds(row['pred2'], top_row['pred2']),\n",
    "                    'pred3_odds': calculate_odds(row['pred3'], top_row['pred3']),\n",
    "                    'pred_C_odds': calculate_odds(row['pred_C'], top_row['pred_C']),\n",
    "                    'pred_X_odds': calculate_odds(row['pred_X'], top_row['pred_X']),\n",
    "                }\n",
    "                temp_data.append(odds_row)\n",
    "            final_data_25_75.extend(temp_data)\n",
    "\n",
    "final_data_25_75_sorted = pd.DataFrame(final_data_25_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_between25_75 = []\n",
    "\n",
    "for variable in pivot_combined_df_between25_75_sorted['Variable'].unique():\n",
    "    variable_df = pivot_combined_df_between25_75_sorted[pivot_combined_df_between25_75_sorted['Variable'] == variable]\n",
    "    for tercile in variable_df['Tercile'].unique():\n",
    "        top_row = variable_df[(variable_df['Group'] == 'top') & (variable_df['Tercile'] == tercile)]\n",
    "        if not top_row.empty:\n",
    "            top_row = top_row.iloc[0]\n",
    "            temp_data = []\n",
    "            for _, row in variable_df[variable_df['Tercile'] == tercile].iterrows():\n",
    "                odds_row = {\n",
    "                    'Variable': row['Variable'],\n",
    "                    'Group': row['Group'],\n",
    "                    'Tercile': row['Tercile'],\n",
    "                    'pred1_t': row['pred1_t'],\n",
    "                    'pred2_t': row['pred2_t'],\n",
    "                    'pred3_t': row['pred3_t'],\n",
    "                    'pred_C_t': row['pred_C_t'],\n",
    "                    'pred_X_t': row['pred_X_t'],\n",
    "                    'pred1_odds': calculate_odds(row['pred1_t'], top_row['pred1_t']),\n",
    "                    'pred2_odds': calculate_odds(row['pred2_t'], top_row['pred2_t']),\n",
    "                    'pred3_odds': calculate_odds(row['pred3_t'], top_row['pred3_t']),\n",
    "                    'pred_C_odds': calculate_odds(row['pred_C_t'], top_row['pred_C_t']),\n",
    "                    'pred_X_odds': calculate_odds(row['pred_X_t'], top_row['pred_X_t']),\n",
    "                }\n",
    "                temp_data.append(odds_row)\n",
    "            final_data_between25_75.extend(temp_data)\n",
    "\n",
    "final_data_between25_75_sorted = pd.DataFrame(final_data_between25_75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_median = []\n",
    "\n",
    "for variable in pivot_combined_df_median_sorted['Variable'].unique():\n",
    "    variable_df = pivot_combined_df_median_sorted[pivot_combined_df_median_sorted['Variable'] == variable]\n",
    "    for pair in variable_df[['Pair1', 'Pair2']].drop_duplicates().values:\n",
    "        pair1, pair2 = pair\n",
    "        top_row = variable_df[(variable_df['Group'] == 'top') & (variable_df['Pair1'] == pair1) & (variable_df['Pair2'] == pair2)]\n",
    "        if not top_row.empty:\n",
    "            top_row = top_row.iloc[0]\n",
    "            temp_data = []\n",
    "            for _, row in variable_df[(variable_df['Pair1'] == pair1) & (variable_df['Pair2'] == pair2)].iterrows():\n",
    "                odds_row = {\n",
    "                    'Variable': row['Variable'],\n",
    "                    'Group': row['Group'],\n",
    "                    'Pair1': row['Pair1'],\n",
    "                    'Pair2': row['Pair2'],\n",
    "                    'pred1': row['pred1'],\n",
    "                    'pred2': row['pred2'],\n",
    "                    'pred3': row['pred3'],\n",
    "                    'pred_C': row['pred_C'],\n",
    "                    'pred_X': row['pred_X'],\n",
    "                    'pred1_odds': calculate_odds(row['pred1'], top_row['pred1']),\n",
    "                    'pred2_odds': calculate_odds(row['pred2'], top_row['pred2']),\n",
    "                    'pred3_odds': calculate_odds(row['pred3'], top_row['pred3']),\n",
    "                    'pred_C_odds': calculate_odds(row['pred_C'], top_row['pred_C']),\n",
    "                    'pred_X_odds': calculate_odds(row['pred_X'], top_row['pred_X']),\n",
    "                }\n",
    "                temp_data.append(odds_row)\n",
    "            final_data_median.extend(temp_data)\n",
    "\n",
    "final_data_median_sorted = pd.DataFrame(final_data_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = ['a1', 'mother_education', 'father_education', 'mother_occupation', 'father_occupation', 'books', 'd14', 'inmigrant_second_gen', \n",
    "                  'public_private', 'capital_island', 'start_schooling_age', 'f12a', 'ESCS_median', 'ESCS_p25_p75']\n",
    "\n",
    "final_data_25_75_sorted['Variable'] = pd.Categorical(final_data_25_75_sorted['Variable'], categories=category_order, ordered=True)\n",
    "final_data_25_75_sorted = final_data_25_75_sorted.sort_values(by='Variable')\n",
    "final_data_25_75_sorted = final_data_25_75_sorted[['Variable', 'Group', 'Percentile', 'pred1', 'pred1_odds', 'pred2', 'pred2_odds', 'pred3', 'pred3_odds', 'pred_C', 'pred_C_odds', 'pred_X', 'pred_X_odds']]\n",
    "final_data_25_75_sorted = final_data_25_75_sorted.sort_values(by=['Percentile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "final_data_between25_75_sorted['Variable'] = pd.Categorical(final_data_between25_75_sorted['Variable'], categories=category_order, ordered=True)\n",
    "final_data_between25_75_sorted = final_data_between25_75_sorted.sort_values(by='Variable')\n",
    "final_data_between25_75_sorted = final_data_between25_75_sorted[['Variable', 'Group', 'Tercile', 'pred1_t', 'pred1_odds', 'pred2_t', 'pred2_odds', 'pred3_t', 'pred3_odds', 'pred_C_t', 'pred_C_odds', 'pred_X_t', 'pred_X_odds']]\n",
    "final_data_between25_75_sorted = final_data_between25_75_sorted.sort_values(by=['Tercile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "final_data_median_sorted['Variable'] = pd.Categorical(final_data_median_sorted['Variable'], categories=category_order, ordered=True)\n",
    "final_data_median_sorted = final_data_median_sorted.sort_values(by='Variable')\n",
    "final_data_median_sorted = final_data_median_sorted[['Variable', 'Group', 'Pair1', 'Pair2', 'pred1', 'pred1_odds', 'pred2', 'pred2_odds', 'pred3', 'pred3_odds', 'pred_C', 'pred_C_odds', 'pred_X', 'pred_X_odds']]\n",
    "final_data_median_sorted = final_data_median_sorted.sort_values(by=['Pair1', 'Pair2', 'Variable', 'Group'], ascending=[True, True, True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel\n",
    "with pd.ExcelWriter(os.path.join('results', 'results.xlsx')) as writer:\n",
    "    final_data_25_75_sorted.to_excel(writer, sheet_name='25_75', index=False, float_format='%.4f')\n",
    "    final_data_median_sorted.to_excel(writer, sheet_name='Median', index=False, float_format='%.4f')\n",
    "    final_data_between25_75_sorted.to_excel(writer, sheet_name='between25_75', index=False, float_format='%.4f')\n",
    "    data.to_excel(writer, sheet_name='data', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOP\n",
    "\n",
    "Inequality of Opportunity is computed by applying an inequality index (Gini, MLD or simple variance) to the set of central moments (specifically, the mean $\\mu$) for the $Y$'s conditional distributions with respect to a sensitive attribute's values. Mathematically:\n",
    "$$IOP = I(w_{i} * \\mu(Y|G_{i}), \\ldots, w_{m} * \\mu(Y|G_{m}))$$ \n",
    "\n",
    "$I$ is the inequality index while $G_{1} \\ldots G_{m}$ are the $m$ different groups of individuals identified by the values a given senstive attribute can have. For example, if _gender_ is a sensitive attribute then the two resulting groups might be $G_{1} = male$ and $G_{2} = female$. In this situation, _IOP_ would be absent if $$I(w_{1} * \\mu(Y|G_{1}), w_{2} * \\mu(Y|G_{2})) = 0$$ or close to 0.\n",
    "\n",
    "Finally, each central moment is weighted by the fraction of samples with a given value of the sensitive attribute. The weights sum up to 1. In the previous example, $w_{1}$ is the fraction of elements with $G = m$ and $w_{2}$ is the fraction of elements with $G = f$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['score_MAT', 'score_LEN', 'score_MAT3', 'score_LEN3', 'a1',\n",
       "       'mother_education', 'father_education', 'mother_occupation',\n",
       "       'father_occupation', 'inmigrant_second_gen', 'start_schooling_age',\n",
       "       'books', 'f12a', 'public_private', 'capital_island', 'd14', 'ESCS',\n",
       "       'score_MATq', 'score_LENq', 'ESCS_median', 'ESCS_p25_p75',\n",
       "       'model1_pred', 'model2_pred', 'Y_t_1_hat', 'ν_hat', 'model3_pred',\n",
       "       'model3_pred_circum', 'mean_circu', 'model3_pred_effort',\n",
       "       'score_MAT_discrete', 'score_MAT_pred1', 'score_MAT_pred2',\n",
       "       'score_MAT_pred3', 'score_MAT_pred_C', 'score_MAT_pred_X',\n",
       "       'score_MAT_pred1_t', 'score_MAT_pred2_t', 'score_MAT_pred3_t',\n",
       "       'score_MAT_pred_C_t', 'score_MAT_pred_X_t'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def compute_accuracy(test_data, model_pred, sa, protected_group, percentile):\n",
    "    # filter gts and preds based on values of the sensitive attributes\n",
    "    # protected group (normally one value) vs non protected group(s) (potentially multiple values)\n",
    "    # compute accuracy for each group\n",
    "\n",
    "    if test_data[sa].isna().sum() > 0:\n",
    "        test_data = test_data.dropna(axis=0)\n",
    "    else:\n",
    "        test_data = test_data.dropna(axis=1)\n",
    "\n",
    "    y_true_protected = test_data.loc[test_data[sa] == protected_group][\"score_MAT_discrete\"].astype(np.int64)\n",
    "    y_pred_protected = test_data.loc[test_data[sa] == protected_group][model_pred].astype(np.int64)\n",
    "\n",
    "    y_true_non_protected = test_data.loc[~(test_data[sa].astype(np.int64) == protected_group)][\"score_MAT_discrete\"]\n",
    "    y_pred_non_protected = test_data.loc[~(test_data[sa].astype(np.int64) == protected_group)][model_pred]\n",
    "\n",
    "    # print(\"#\" * 25)\n",
    "    # print(f\"Confusion matrix, protected group ({sa}):\")\n",
    "    # print(confusion_matrix(y_true_protected, y_pred_protected))\n",
    "    accuracy_protected = round(accuracy_score(y_true_protected, y_pred_protected), 2)\n",
    "    # print(accuracy_protected)\n",
    "\n",
    "    # print(f\"Confusion matrix, non protected group ({sa}):\")\n",
    "    # print(confusion_matrix(y_true_non_protected, y_pred_non_protected))\n",
    "    accuracy_non_protected = round(accuracy_score(y_true_non_protected, y_pred_non_protected), 2)\n",
    "    # print(accuracy_non_protected)\n",
    "\n",
    "    return accuracy_protected, accuracy_non_protected\n",
    "\n",
    "def run_experiments(test_data, percentile, ineq_index):\n",
    "    \n",
    "    percentiles = test_data['score_MAT'].quantile([0.25, 0.75])\n",
    "    test_data.loc[:, 'percentile_bin'] = pd.cut(test_data['score_MAT'], \n",
    "                                                bins=[test_data['score_MAT'].min()] + list(percentiles) + [test_data['score_MAT'].max()], \n",
    "                                                include_lowest=True)\n",
    "\n",
    "    groups = [group for _, group in test_data.groupby('percentile_bin')]\n",
    "    percentile_df = {\"below-25\": groups[0], \"between-25-75\": groups[1], \"above-75\": groups[2]}\n",
    "\n",
    "    data = percentile_df[percentile]\n",
    "\n",
    "    sensitive_attrs = ['a1', 'mother_education', 'father_education',\n",
    "       'mother_occupation', 'father_occupation', 'inmigrant_second_gen',\n",
    "       'start_schooling_age', 'books', 'f12a', 'public_private',\n",
    "       'capital_island', 'd14', \"ESCS_median\", \"ESCS_p25_p75\"]\n",
    "\n",
    "    columns = [\"Model 1\", \"Model 2\", \"Model 3\", \"Circumstances\", \"Effort\"]\n",
    "    # model_preds_acc = [f\"score_MAT_{x}\" for x in [\"pred1\", \"pred2\", \"pred3\", \"pred_C\", \"pred_X\", \"pred1_t\", \"pred2_t\", \"pred3_t\", \"pred_C_t\", \"pred_X_t\"]]\n",
    "    model_preds = [\"model1_pred\", \"model2_pred\", \"model3_pred\", \"model3_pred_circum\", \"model3_pred_effort\"]\n",
    "    preds = [\"pred1\", \"pred2\", \"pred3\", \"pred_C\", \"pred_X\"]\n",
    "\n",
    "    model_preds_acc = []\n",
    "    columns_acc = []\n",
    "    if percentile == \"below-25\" or percentile == \"above-75\":\n",
    "        model_preds_acc = [f\"score_MAT_{x}\" for x in preds]\n",
    "        columns_acc = columns\n",
    "    else:\n",
    "        columns_acc = [x + \" terciles\" for x in columns]\n",
    "        model_preds_acc = [f\"score_MAT_{x}_t\" for x in preds]\n",
    "    \n",
    "    model_pred_rename = {mp: col for mp, col in zip(model_preds, columns)}\n",
    "    model_pred_acc_rename = {mpa: col for mpa, col in zip(model_preds_acc, columns_acc)}\n",
    "\n",
    "    sensitive_attrs_values = {\n",
    "         \"a1\": 1,\n",
    "         \"mother_education\": 4,\n",
    "         \"father_education\": 4,\n",
    "         \"mother_occupation\": 4,\n",
    "         \"father_occupation\": 4,\n",
    "         \"inmigrant_second_gen\": 1, \n",
    "         \"start_schooling_age\": 1, \n",
    "         \"books\": 4, \n",
    "         \"f12a\": 5,\n",
    "         \"public_private\": 1,\n",
    "         \"capital_island\": 1,\n",
    "         \"d14\": 1,\n",
    "         \"ESCS_median\": 1,\n",
    "         \"ESCS_p25_p75\": 1\n",
    "    }\n",
    "    \n",
    "    df = {}\n",
    "    for mp in model_preds:\n",
    "        col = []\n",
    "        data.loc[:, \"label\"] = binarise_predictions(data[mp], percentile)\n",
    "        for sa in sensitive_attrs:\n",
    "            col.append(iop(data, sa, ineq_index=ineq_index))\n",
    "        df[model_pred_rename[mp]] = col\n",
    "\n",
    "    df_accuracy = {}\n",
    "    print(model_preds_acc)\n",
    "    for mp in model_preds_acc:\n",
    "        col_acc = []\n",
    "        for sa in sensitive_attrs:\n",
    "            col_acc.append(compute_accuracy(data, mp, sa, sensitive_attrs_values[sa], percentile))\n",
    "        df_accuracy[model_pred_acc_rename[mp]] = col_acc\n",
    "    return pd.DataFrame(df, index=sensitive_attrs), pd.DataFrame(df_accuracy, index=sensitive_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below 25th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/3976309434.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groups = [group for _, group in test_data.groupby('percentile_bin')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score_MAT_pred1', 'score_MAT_pred2', 'score_MAT_pred3', 'score_MAT_pred_C', 'score_MAT_pred_X']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.013288</td>\n",
       "      <td>0.064155</td>\n",
       "      <td>0.022891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>0.177270</td>\n",
       "      <td>0.171258</td>\n",
       "      <td>0.180187</td>\n",
       "      <td>0.422084</td>\n",
       "      <td>0.335228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>0.317401</td>\n",
       "      <td>0.376956</td>\n",
       "      <td>0.360833</td>\n",
       "      <td>0.445067</td>\n",
       "      <td>0.205632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>0.617158</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.621921</td>\n",
       "      <td>0.601008</td>\n",
       "      <td>0.641561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>0.641799</td>\n",
       "      <td>0.635658</td>\n",
       "      <td>0.636558</td>\n",
       "      <td>0.572376</td>\n",
       "      <td>0.658388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>0.496497</td>\n",
       "      <td>0.496497</td>\n",
       "      <td>0.496497</td>\n",
       "      <td>0.498637</td>\n",
       "      <td>0.493450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>0.464705</td>\n",
       "      <td>0.421553</td>\n",
       "      <td>0.427907</td>\n",
       "      <td>0.373072</td>\n",
       "      <td>0.504964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>0.438157</td>\n",
       "      <td>0.516553</td>\n",
       "      <td>0.538544</td>\n",
       "      <td>0.583135</td>\n",
       "      <td>0.423724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>0.574969</td>\n",
       "      <td>0.574675</td>\n",
       "      <td>0.563480</td>\n",
       "      <td>0.592797</td>\n",
       "      <td>0.575497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>0.463490</td>\n",
       "      <td>0.475487</td>\n",
       "      <td>0.472556</td>\n",
       "      <td>0.486780</td>\n",
       "      <td>0.433564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>0.462203</td>\n",
       "      <td>0.470266</td>\n",
       "      <td>0.460085</td>\n",
       "      <td>0.466314</td>\n",
       "      <td>0.472186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>0.336128</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.388719</td>\n",
       "      <td>0.425773</td>\n",
       "      <td>0.277011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>0.277028</td>\n",
       "      <td>0.348113</td>\n",
       "      <td>0.348113</td>\n",
       "      <td>0.465484</td>\n",
       "      <td>0.175908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>0.360859</td>\n",
       "      <td>0.434756</td>\n",
       "      <td>0.446187</td>\n",
       "      <td>0.499996</td>\n",
       "      <td>0.269211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "a1                    0.003667  0.005970  0.013288       0.064155  0.022891\n",
       "mother_education      0.177270  0.171258  0.180187       0.422084  0.335228\n",
       "father_education      0.317401  0.376956  0.360833       0.445067  0.205632\n",
       "mother_occupation     0.617158  0.616969  0.621921       0.601008  0.641561\n",
       "father_occupation     0.641799  0.635658  0.636558       0.572376  0.658388\n",
       "inmigrant_second_gen  0.496497  0.496497  0.496497       0.498637  0.493450\n",
       "start_schooling_age   0.464705  0.421553  0.427907       0.373072  0.504964\n",
       "books                 0.438157  0.516553  0.538544       0.583135  0.423724\n",
       "f12a                  0.574969  0.574675  0.563480       0.592797  0.575497\n",
       "public_private        0.463490  0.475487  0.472556       0.486780  0.433564\n",
       "capital_island        0.462203  0.470266  0.460085       0.466314  0.472186\n",
       "d14                   0.336128  0.342273  0.388719       0.425773  0.277011\n",
       "ESCS_median           0.277028  0.348113  0.348113       0.465484  0.175908\n",
       "ESCS_p25_p75          0.360859  0.434756  0.446187       0.499996  0.269211"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_below_25, df_acc_below_25 = run_experiments(test_data, percentile=\"below-25\", ineq_index=\"gini\")\n",
    "df_below_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>(0.56, 0.47)</td>\n",
       "      <td>(0.51, 0.48)</td>\n",
       "      <td>(0.53, 0.49)</td>\n",
       "      <td>(0.29, 0.41)</td>\n",
       "      <td>(0.53, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>(0.41, 0.58)</td>\n",
       "      <td>(0.31, 0.6)</td>\n",
       "      <td>(0.31, 0.62)</td>\n",
       "      <td>(0.05, 0.52)</td>\n",
       "      <td>(0.5, 0.49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>(0.37, 0.56)</td>\n",
       "      <td>(0.18, 0.59)</td>\n",
       "      <td>(0.24, 0.59)</td>\n",
       "      <td>(0.02, 0.44)</td>\n",
       "      <td>(0.57, 0.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>(0.46, 0.53)</td>\n",
       "      <td>(0.44, 0.51)</td>\n",
       "      <td>(0.45, 0.53)</td>\n",
       "      <td>(0.23, 0.38)</td>\n",
       "      <td>(0.49, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>(0.43, 0.55)</td>\n",
       "      <td>(0.37, 0.54)</td>\n",
       "      <td>(0.39, 0.55)</td>\n",
       "      <td>(0.25, 0.38)</td>\n",
       "      <td>(0.47, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>(0.51, 0.59)</td>\n",
       "      <td>(0.5, 0.41)</td>\n",
       "      <td>(0.51, 0.56)</td>\n",
       "      <td>(0.36, 0.19)</td>\n",
       "      <td>(0.49, 0.52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>(0.52, 0.51)</td>\n",
       "      <td>(0.48, 0.52)</td>\n",
       "      <td>(0.48, 0.55)</td>\n",
       "      <td>(0.22, 0.54)</td>\n",
       "      <td>(0.53, 0.44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>(0.38, 0.54)</td>\n",
       "      <td>(0.29, 0.54)</td>\n",
       "      <td>(0.32, 0.55)</td>\n",
       "      <td>(0.03, 0.41)</td>\n",
       "      <td>(0.53, 0.49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>(0.55, 0.5)</td>\n",
       "      <td>(0.49, 0.5)</td>\n",
       "      <td>(0.51, 0.51)</td>\n",
       "      <td>(0.28, 0.39)</td>\n",
       "      <td>(0.56, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>(0.39, 0.55)</td>\n",
       "      <td>(0.33, 0.54)</td>\n",
       "      <td>(0.3, 0.57)</td>\n",
       "      <td>(0.1, 0.41)</td>\n",
       "      <td>(0.47, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>(0.5, 0.62)</td>\n",
       "      <td>(0.48, 0.6)</td>\n",
       "      <td>(0.49, 0.64)</td>\n",
       "      <td>(0.32, 0.57)</td>\n",
       "      <td>(0.49, 0.55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>(0.46, 0.54)</td>\n",
       "      <td>(0.45, 0.52)</td>\n",
       "      <td>(0.43, 0.55)</td>\n",
       "      <td>(0.17, 0.43)</td>\n",
       "      <td>(0.56, 0.47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>(0.58, 0.44)</td>\n",
       "      <td>(0.62, 0.33)</td>\n",
       "      <td>(0.63, 0.34)</td>\n",
       "      <td>(0.54, 0.08)</td>\n",
       "      <td>(0.47, 0.53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>(0.52, 0.37)</td>\n",
       "      <td>(0.61, 0.25)</td>\n",
       "      <td>(0.62, 0.28)</td>\n",
       "      <td>(0.72, 0.02)</td>\n",
       "      <td>(0.4, 0.51)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model 1       Model 2       Model 3 Circumstances  \\\n",
       "a1                    (0.56, 0.47)  (0.51, 0.48)  (0.53, 0.49)  (0.29, 0.41)   \n",
       "mother_education      (0.41, 0.58)   (0.31, 0.6)  (0.31, 0.62)  (0.05, 0.52)   \n",
       "father_education      (0.37, 0.56)  (0.18, 0.59)  (0.24, 0.59)  (0.02, 0.44)   \n",
       "mother_occupation     (0.46, 0.53)  (0.44, 0.51)  (0.45, 0.53)  (0.23, 0.38)   \n",
       "father_occupation     (0.43, 0.55)  (0.37, 0.54)  (0.39, 0.55)  (0.25, 0.38)   \n",
       "inmigrant_second_gen  (0.51, 0.59)   (0.5, 0.41)  (0.51, 0.56)  (0.36, 0.19)   \n",
       "start_schooling_age   (0.52, 0.51)  (0.48, 0.52)  (0.48, 0.55)  (0.22, 0.54)   \n",
       "books                 (0.38, 0.54)  (0.29, 0.54)  (0.32, 0.55)  (0.03, 0.41)   \n",
       "f12a                   (0.55, 0.5)   (0.49, 0.5)  (0.51, 0.51)  (0.28, 0.39)   \n",
       "public_private        (0.39, 0.55)  (0.33, 0.54)   (0.3, 0.57)   (0.1, 0.41)   \n",
       "capital_island         (0.5, 0.62)   (0.48, 0.6)  (0.49, 0.64)  (0.32, 0.57)   \n",
       "d14                   (0.46, 0.54)  (0.45, 0.52)  (0.43, 0.55)  (0.17, 0.43)   \n",
       "ESCS_median           (0.58, 0.44)  (0.62, 0.33)  (0.63, 0.34)  (0.54, 0.08)   \n",
       "ESCS_p25_p75          (0.52, 0.37)  (0.61, 0.25)  (0.62, 0.28)  (0.72, 0.02)   \n",
       "\n",
       "                            Effort  \n",
       "a1                    (0.53, 0.46)  \n",
       "mother_education       (0.5, 0.49)  \n",
       "father_education      (0.57, 0.48)  \n",
       "mother_occupation      (0.49, 0.5)  \n",
       "father_occupation      (0.47, 0.5)  \n",
       "inmigrant_second_gen  (0.49, 0.52)  \n",
       "start_schooling_age   (0.53, 0.44)  \n",
       "books                 (0.53, 0.49)  \n",
       "f12a                  (0.56, 0.46)  \n",
       "public_private         (0.47, 0.5)  \n",
       "capital_island        (0.49, 0.55)  \n",
       "d14                   (0.56, 0.47)  \n",
       "ESCS_median           (0.47, 0.53)  \n",
       "ESCS_p25_p75           (0.4, 0.51)  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_below_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between 25th and 75th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/3976309434.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groups = [group for _, group in test_data.groupby('percentile_bin')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score_MAT_pred1_t', 'score_MAT_pred2_t', 'score_MAT_pred3_t', 'score_MAT_pred_C_t', 'score_MAT_pred_X_t']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>0.068460</td>\n",
       "      <td>0.072167</td>\n",
       "      <td>0.072167</td>\n",
       "      <td>0.033779</td>\n",
       "      <td>0.076950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>0.477919</td>\n",
       "      <td>0.485938</td>\n",
       "      <td>0.492089</td>\n",
       "      <td>0.481957</td>\n",
       "      <td>0.497218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>0.238316</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>0.237338</td>\n",
       "      <td>0.250410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>0.631889</td>\n",
       "      <td>0.638666</td>\n",
       "      <td>0.639523</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.631957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>0.643534</td>\n",
       "      <td>0.647229</td>\n",
       "      <td>0.650855</td>\n",
       "      <td>0.654883</td>\n",
       "      <td>0.642655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>0.494592</td>\n",
       "      <td>0.494364</td>\n",
       "      <td>0.494579</td>\n",
       "      <td>0.492614</td>\n",
       "      <td>0.494149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>0.546045</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.552330</td>\n",
       "      <td>0.553901</td>\n",
       "      <td>0.551849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>0.394048</td>\n",
       "      <td>0.406741</td>\n",
       "      <td>0.398860</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.376933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.588434</td>\n",
       "      <td>0.593112</td>\n",
       "      <td>0.573892</td>\n",
       "      <td>0.582981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>0.409370</td>\n",
       "      <td>0.412290</td>\n",
       "      <td>0.414391</td>\n",
       "      <td>0.436434</td>\n",
       "      <td>0.418544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>0.478061</td>\n",
       "      <td>0.476123</td>\n",
       "      <td>0.478002</td>\n",
       "      <td>0.476123</td>\n",
       "      <td>0.478466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>0.266302</td>\n",
       "      <td>0.271192</td>\n",
       "      <td>0.263751</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.285832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.056859</td>\n",
       "      <td>0.038934</td>\n",
       "      <td>0.042905</td>\n",
       "      <td>0.020694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "a1                    0.068460  0.072167  0.072167       0.033779  0.076950\n",
       "mother_education      0.477919  0.485938  0.492089       0.481957  0.497218\n",
       "father_education      0.238316  0.238311  0.238311       0.237338  0.250410\n",
       "mother_occupation     0.631889  0.638666  0.639523       0.653763  0.631957\n",
       "father_occupation     0.643534  0.647229  0.650855       0.654883  0.642655\n",
       "inmigrant_second_gen  0.494592  0.494364  0.494579       0.492614  0.494149\n",
       "start_schooling_age   0.546045  0.545798  0.552330       0.553901  0.551849\n",
       "books                 0.394048  0.406741  0.398860       0.498889  0.376933\n",
       "f12a                  0.576416  0.588434  0.593112       0.573892  0.582981\n",
       "public_private        0.409370  0.412290  0.414391       0.436434  0.418544\n",
       "capital_island        0.478061  0.476123  0.478002       0.476123  0.478466\n",
       "d14                   0.266302  0.271192  0.263751       0.310700  0.285832\n",
       "ESCS_median           0.003614  0.004831  0.000000       0.002415  0.014493\n",
       "ESCS_p25_p75          0.054100  0.056859  0.038934       0.042905  0.020694"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_between_25_75, df_acc_between_25_75 = run_experiments(test_data, percentile=\"between-25-75\", ineq_index=\"gini\")\n",
    "df_between_25_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1 terciles</th>\n",
       "      <th>Model 2 terciles</th>\n",
       "      <th>Model 3 terciles</th>\n",
       "      <th>Circumstances terciles</th>\n",
       "      <th>Effort terciles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>(0.47, 0.42)</td>\n",
       "      <td>(0.46, 0.45)</td>\n",
       "      <td>(0.47, 0.43)</td>\n",
       "      <td>(0.43, 0.34)</td>\n",
       "      <td>(0.43, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>(0.44, 0.45)</td>\n",
       "      <td>(0.47, 0.44)</td>\n",
       "      <td>(0.49, 0.42)</td>\n",
       "      <td>(0.53, 0.27)</td>\n",
       "      <td>(0.36, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>(0.43, 0.45)</td>\n",
       "      <td>(0.52, 0.42)</td>\n",
       "      <td>(0.49, 0.43)</td>\n",
       "      <td>(0.45, 0.36)</td>\n",
       "      <td>(0.33, 0.45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>(0.39, 0.46)</td>\n",
       "      <td>(0.46, 0.45)</td>\n",
       "      <td>(0.47, 0.44)</td>\n",
       "      <td>(0.5, 0.35)</td>\n",
       "      <td>(0.31, 0.45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>(0.4, 0.47)</td>\n",
       "      <td>(0.49, 0.44)</td>\n",
       "      <td>(0.47, 0.44)</td>\n",
       "      <td>(0.47, 0.36)</td>\n",
       "      <td>(0.35, 0.44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>(0.45, 0.43)</td>\n",
       "      <td>(0.45, 0.48)</td>\n",
       "      <td>(0.45, 0.43)</td>\n",
       "      <td>(0.4, 0.27)</td>\n",
       "      <td>(0.42, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>(0.43, 0.47)</td>\n",
       "      <td>(0.46, 0.46)</td>\n",
       "      <td>(0.45, 0.46)</td>\n",
       "      <td>(0.42, 0.32)</td>\n",
       "      <td>(0.41, 0.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>(0.49, 0.43)</td>\n",
       "      <td>(0.58, 0.42)</td>\n",
       "      <td>(0.57, 0.41)</td>\n",
       "      <td>(0.58, 0.33)</td>\n",
       "      <td>(0.38, 0.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>(0.46, 0.43)</td>\n",
       "      <td>(0.5, 0.43)</td>\n",
       "      <td>(0.49, 0.42)</td>\n",
       "      <td>(0.44, 0.35)</td>\n",
       "      <td>(0.4, 0.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>(0.41, 0.46)</td>\n",
       "      <td>(0.43, 0.46)</td>\n",
       "      <td>(0.47, 0.44)</td>\n",
       "      <td>(0.47, 0.36)</td>\n",
       "      <td>(0.38, 0.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>(0.45, 0.43)</td>\n",
       "      <td>(0.46, 0.45)</td>\n",
       "      <td>(0.46, 0.37)</td>\n",
       "      <td>(0.4, 0.3)</td>\n",
       "      <td>(0.42, 0.41)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>(0.43, 0.46)</td>\n",
       "      <td>(0.43, 0.47)</td>\n",
       "      <td>(0.47, 0.44)</td>\n",
       "      <td>(0.48, 0.34)</td>\n",
       "      <td>(0.39, 0.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>(0.46, 0.43)</td>\n",
       "      <td>(0.41, 0.5)</td>\n",
       "      <td>(0.4, 0.5)</td>\n",
       "      <td>(0.29, 0.48)</td>\n",
       "      <td>(0.46, 0.37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>(0.47, 0.42)</td>\n",
       "      <td>(0.41, 0.53)</td>\n",
       "      <td>(0.4, 0.51)</td>\n",
       "      <td>(0.18, 0.55)</td>\n",
       "      <td>(0.48, 0.34)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model 1 terciles Model 2 terciles Model 3 terciles  \\\n",
       "a1                       (0.47, 0.42)     (0.46, 0.45)     (0.47, 0.43)   \n",
       "mother_education         (0.44, 0.45)     (0.47, 0.44)     (0.49, 0.42)   \n",
       "father_education         (0.43, 0.45)     (0.52, 0.42)     (0.49, 0.43)   \n",
       "mother_occupation        (0.39, 0.46)     (0.46, 0.45)     (0.47, 0.44)   \n",
       "father_occupation         (0.4, 0.47)     (0.49, 0.44)     (0.47, 0.44)   \n",
       "inmigrant_second_gen     (0.45, 0.43)     (0.45, 0.48)     (0.45, 0.43)   \n",
       "start_schooling_age      (0.43, 0.47)     (0.46, 0.46)     (0.45, 0.46)   \n",
       "books                    (0.49, 0.43)     (0.58, 0.42)     (0.57, 0.41)   \n",
       "f12a                     (0.46, 0.43)      (0.5, 0.43)     (0.49, 0.42)   \n",
       "public_private           (0.41, 0.46)     (0.43, 0.46)     (0.47, 0.44)   \n",
       "capital_island           (0.45, 0.43)     (0.46, 0.45)     (0.46, 0.37)   \n",
       "d14                      (0.43, 0.46)     (0.43, 0.47)     (0.47, 0.44)   \n",
       "ESCS_median              (0.46, 0.43)      (0.41, 0.5)       (0.4, 0.5)   \n",
       "ESCS_p25_p75             (0.47, 0.42)     (0.41, 0.53)      (0.4, 0.51)   \n",
       "\n",
       "                     Circumstances terciles Effort terciles  \n",
       "a1                             (0.43, 0.34)     (0.43, 0.4)  \n",
       "mother_education               (0.53, 0.27)    (0.36, 0.46)  \n",
       "father_education               (0.45, 0.36)    (0.33, 0.45)  \n",
       "mother_occupation               (0.5, 0.35)    (0.31, 0.45)  \n",
       "father_occupation              (0.47, 0.36)    (0.35, 0.44)  \n",
       "inmigrant_second_gen            (0.4, 0.27)     (0.42, 0.4)  \n",
       "start_schooling_age            (0.42, 0.32)    (0.41, 0.43)  \n",
       "books                          (0.58, 0.33)    (0.38, 0.43)  \n",
       "f12a                           (0.44, 0.35)     (0.4, 0.43)  \n",
       "public_private                 (0.47, 0.36)    (0.38, 0.43)  \n",
       "capital_island                   (0.4, 0.3)    (0.42, 0.41)  \n",
       "d14                            (0.48, 0.34)    (0.39, 0.43)  \n",
       "ESCS_median                    (0.29, 0.48)    (0.46, 0.37)  \n",
       "ESCS_p25_p75                   (0.18, 0.55)    (0.48, 0.34)  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_between_25_75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above 75th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/t1v535y91l76l6x3j7zj5wb00000gn/T/ipykernel_1852/3976309434.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groups = [group for _, group in test_data.groupby('percentile_bin')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score_MAT_pred1', 'score_MAT_pred2', 'score_MAT_pred3', 'score_MAT_pred_C', 'score_MAT_pred_X']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>0.056377</td>\n",
       "      <td>0.113163</td>\n",
       "      <td>0.075386</td>\n",
       "      <td>0.113163</td>\n",
       "      <td>0.046842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>0.644870</td>\n",
       "      <td>0.690410</td>\n",
       "      <td>0.681385</td>\n",
       "      <td>0.748328</td>\n",
       "      <td>0.576701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>0.510521</td>\n",
       "      <td>0.595713</td>\n",
       "      <td>0.573782</td>\n",
       "      <td>0.704153</td>\n",
       "      <td>0.410336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>0.633314</td>\n",
       "      <td>0.613446</td>\n",
       "      <td>0.613446</td>\n",
       "      <td>0.586998</td>\n",
       "      <td>0.656412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>0.590974</td>\n",
       "      <td>0.552272</td>\n",
       "      <td>0.562781</td>\n",
       "      <td>0.506428</td>\n",
       "      <td>0.621794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>0.494910</td>\n",
       "      <td>0.493085</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>0.494910</td>\n",
       "      <td>0.492146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>0.606086</td>\n",
       "      <td>0.613135</td>\n",
       "      <td>0.613135</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.575507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>0.324147</td>\n",
       "      <td>0.319927</td>\n",
       "      <td>0.286426</td>\n",
       "      <td>0.513097</td>\n",
       "      <td>0.391308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>0.614686</td>\n",
       "      <td>0.622350</td>\n",
       "      <td>0.623743</td>\n",
       "      <td>0.669968</td>\n",
       "      <td>0.610641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>0.315508</td>\n",
       "      <td>0.315508</td>\n",
       "      <td>0.295681</td>\n",
       "      <td>0.183301</td>\n",
       "      <td>0.358874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>0.488712</td>\n",
       "      <td>0.480805</td>\n",
       "      <td>0.485635</td>\n",
       "      <td>0.497320</td>\n",
       "      <td>0.479135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>0.132521</td>\n",
       "      <td>0.150273</td>\n",
       "      <td>0.105306</td>\n",
       "      <td>0.096374</td>\n",
       "      <td>0.201730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>0.145070</td>\n",
       "      <td>0.243539</td>\n",
       "      <td>0.234759</td>\n",
       "      <td>0.444630</td>\n",
       "      <td>0.023099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>0.260040</td>\n",
       "      <td>0.370350</td>\n",
       "      <td>0.357424</td>\n",
       "      <td>0.491732</td>\n",
       "      <td>0.042005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "a1                    0.056377  0.113163  0.075386       0.113163  0.046842\n",
       "mother_education      0.644870  0.690410  0.681385       0.748328  0.576701\n",
       "father_education      0.510521  0.595713  0.573782       0.704153  0.410336\n",
       "mother_occupation     0.633314  0.613446  0.613446       0.586998  0.656412\n",
       "father_occupation     0.590974  0.552272  0.562781       0.506428  0.621794\n",
       "inmigrant_second_gen  0.494910  0.493085  0.494006       0.494910  0.492146\n",
       "start_schooling_age   0.606086  0.613135  0.613135       0.646822  0.575507\n",
       "books                 0.324147  0.319927  0.286426       0.513097  0.391308\n",
       "f12a                  0.614686  0.622350  0.623743       0.669968  0.610641\n",
       "public_private        0.315508  0.315508  0.295681       0.183301  0.358874\n",
       "capital_island        0.488712  0.480805  0.485635       0.497320  0.479135\n",
       "d14                   0.132521  0.150273  0.105306       0.096374  0.201730\n",
       "ESCS_median           0.145070  0.243539  0.234759       0.444630  0.023099\n",
       "ESCS_p25_p75          0.260040  0.370350  0.357424       0.491732  0.042005"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_above_75, df_acc_above_75 = run_experiments(test_data, percentile=\"above-75\", ineq_index=\"gini\")\n",
    "df_above_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>(0.52, 0.48)</td>\n",
       "      <td>(0.51, 0.47)</td>\n",
       "      <td>(0.53, 0.46)</td>\n",
       "      <td>(0.41, 0.29)</td>\n",
       "      <td>(0.47, 0.47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>(0.57, 0.41)</td>\n",
       "      <td>(0.63, 0.31)</td>\n",
       "      <td>(0.63, 0.32)</td>\n",
       "      <td>(0.6, 0.03)</td>\n",
       "      <td>(0.46, 0.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>(0.57, 0.45)</td>\n",
       "      <td>(0.64, 0.37)</td>\n",
       "      <td>(0.62, 0.41)</td>\n",
       "      <td>(0.63, 0.14)</td>\n",
       "      <td>(0.45, 0.49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>(0.6, 0.46)</td>\n",
       "      <td>(0.62, 0.44)</td>\n",
       "      <td>(0.64, 0.45)</td>\n",
       "      <td>(0.64, 0.25)</td>\n",
       "      <td>(0.5, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>(0.62, 0.43)</td>\n",
       "      <td>(0.67, 0.4)</td>\n",
       "      <td>(0.65, 0.42)</td>\n",
       "      <td>(0.55, 0.25)</td>\n",
       "      <td>(0.48, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>(0.5, 0.47)</td>\n",
       "      <td>(0.5, 0.41)</td>\n",
       "      <td>(0.51, 0.41)</td>\n",
       "      <td>(0.36, 0.25)</td>\n",
       "      <td>(0.47, 0.44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>(0.53, 0.41)</td>\n",
       "      <td>(0.54, 0.36)</td>\n",
       "      <td>(0.55, 0.35)</td>\n",
       "      <td>(0.42, 0.16)</td>\n",
       "      <td>(0.46, 0.49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>(0.6, 0.46)</td>\n",
       "      <td>(0.69, 0.42)</td>\n",
       "      <td>(0.67, 0.44)</td>\n",
       "      <td>(0.79, 0.19)</td>\n",
       "      <td>(0.44, 0.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>(0.53, 0.48)</td>\n",
       "      <td>(0.54, 0.44)</td>\n",
       "      <td>(0.55, 0.46)</td>\n",
       "      <td>(0.46, 0.25)</td>\n",
       "      <td>(0.48, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>(0.51, 0.49)</td>\n",
       "      <td>(0.56, 0.46)</td>\n",
       "      <td>(0.56, 0.47)</td>\n",
       "      <td>(0.55, 0.26)</td>\n",
       "      <td>(0.46, 0.47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>(0.5, 0.52)</td>\n",
       "      <td>(0.48, 0.56)</td>\n",
       "      <td>(0.5, 0.48)</td>\n",
       "      <td>(0.37, 0.2)</td>\n",
       "      <td>(0.47, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>(0.53, 0.48)</td>\n",
       "      <td>(0.53, 0.47)</td>\n",
       "      <td>(0.58, 0.45)</td>\n",
       "      <td>(0.56, 0.22)</td>\n",
       "      <td>(0.48, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>(0.41, 0.57)</td>\n",
       "      <td>(0.34, 0.61)</td>\n",
       "      <td>(0.37, 0.61)</td>\n",
       "      <td>(0.08, 0.57)</td>\n",
       "      <td>(0.47, 0.47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>(0.42, 0.57)</td>\n",
       "      <td>(0.28, 0.69)</td>\n",
       "      <td>(0.32, 0.67)</td>\n",
       "      <td>(0.03, 0.82)</td>\n",
       "      <td>(0.54, 0.43)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model 1       Model 2       Model 3 Circumstances  \\\n",
       "a1                    (0.52, 0.48)  (0.51, 0.47)  (0.53, 0.46)  (0.41, 0.29)   \n",
       "mother_education      (0.57, 0.41)  (0.63, 0.31)  (0.63, 0.32)   (0.6, 0.03)   \n",
       "father_education      (0.57, 0.45)  (0.64, 0.37)  (0.62, 0.41)  (0.63, 0.14)   \n",
       "mother_occupation      (0.6, 0.46)  (0.62, 0.44)  (0.64, 0.45)  (0.64, 0.25)   \n",
       "father_occupation     (0.62, 0.43)   (0.67, 0.4)  (0.65, 0.42)  (0.55, 0.25)   \n",
       "inmigrant_second_gen   (0.5, 0.47)   (0.5, 0.41)  (0.51, 0.41)  (0.36, 0.25)   \n",
       "start_schooling_age   (0.53, 0.41)  (0.54, 0.36)  (0.55, 0.35)  (0.42, 0.16)   \n",
       "books                  (0.6, 0.46)  (0.69, 0.42)  (0.67, 0.44)  (0.79, 0.19)   \n",
       "f12a                  (0.53, 0.48)  (0.54, 0.44)  (0.55, 0.46)  (0.46, 0.25)   \n",
       "public_private        (0.51, 0.49)  (0.56, 0.46)  (0.56, 0.47)  (0.55, 0.26)   \n",
       "capital_island         (0.5, 0.52)  (0.48, 0.56)   (0.5, 0.48)   (0.37, 0.2)   \n",
       "d14                   (0.53, 0.48)  (0.53, 0.47)  (0.58, 0.45)  (0.56, 0.22)   \n",
       "ESCS_median           (0.41, 0.57)  (0.34, 0.61)  (0.37, 0.61)  (0.08, 0.57)   \n",
       "ESCS_p25_p75          (0.42, 0.57)  (0.28, 0.69)  (0.32, 0.67)  (0.03, 0.82)   \n",
       "\n",
       "                            Effort  \n",
       "a1                    (0.47, 0.47)  \n",
       "mother_education      (0.46, 0.48)  \n",
       "father_education      (0.45, 0.49)  \n",
       "mother_occupation      (0.5, 0.46)  \n",
       "father_occupation     (0.48, 0.46)  \n",
       "inmigrant_second_gen  (0.47, 0.44)  \n",
       "start_schooling_age   (0.46, 0.49)  \n",
       "books                 (0.44, 0.48)  \n",
       "f12a                  (0.48, 0.46)  \n",
       "public_private        (0.46, 0.47)  \n",
       "capital_island         (0.47, 0.5)  \n",
       "d14                   (0.48, 0.46)  \n",
       "ESCS_median           (0.47, 0.47)  \n",
       "ESCS_p25_p75          (0.54, 0.43)  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_above_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_means = np.concatenate([\n",
    "    df_below_25.mean(axis=0).to_numpy().reshape((1, df_below_25.shape[1])),\n",
    "    df_above_75.mean(axis=0).to_numpy().reshape((1, df_above_75.shape[1])),\n",
    "    df_between_25_75.mean(axis=0).to_numpy().reshape((1, df_between_25_75.shape[1]))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>below_25</th>\n",
       "      <td>0.402238</td>\n",
       "      <td>0.420499</td>\n",
       "      <td>0.425348</td>\n",
       "      <td>0.464048</td>\n",
       "      <td>0.392087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>above_75</th>\n",
       "      <td>0.415552</td>\n",
       "      <td>0.440998</td>\n",
       "      <td>0.428778</td>\n",
       "      <td>0.478373</td>\n",
       "      <td>0.391895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between_25_75</th>\n",
       "      <td>0.377333</td>\n",
       "      <td>0.381353</td>\n",
       "      <td>0.380493</td>\n",
       "      <td>0.389257</td>\n",
       "      <td>0.380224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "below_25       0.402238  0.420499  0.425348       0.464048  0.392087\n",
       "above_75       0.415552  0.440998  0.428778       0.478373  0.391895\n",
       "between_25_75  0.377333  0.381353  0.380493       0.389257  0.380224"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means = pd.DataFrame(np_means, \n",
    "                        index=[\"below_25\", \"above_75\", \"between_25_75\"], \n",
    "                        columns=[\"Model 1\", \"Model 2\", \"Model 3\", \"Circumstances\", \"Effort\"])\n",
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
