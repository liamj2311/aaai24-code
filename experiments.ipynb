{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import os\n",
    "import wget\n",
    "from sklearn.metrics import recall_score\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We have a database (ULL_database) with information about primary and secondary education students in the Canary Islands \n",
    "for 4 academic years. There is information about their academic performance and \n",
    "contextual information (about their families, teachers, and school). The database contains a subset of data \n",
    "in the form of panel data, meaning information about the same students at different points in time (ULL_panel_data).\n",
    "\n",
    "Machine learning algorithms can be used to predict at-risk students. \n",
    "A student is considered at risk if they are anticipated to have low academic performance in the future. \n",
    "Detecting these students would allow for corrective measures to be taken in advance.\n",
    "\n",
    "As a measure of academic performance, we have the variables \"scores\".\n",
    "We have academic performance in Mathematics and in Spanish Language\n",
    "\n",
    "We specify a model to predict at-risk students. Utilizing the panel data,\n",
    "the model aims to forecast whether the student will be at risk in the future (in 6th grade)\n",
    "based on various predictors of current academic performance (3rd grade).\n",
    "\n",
    "Each observation (row) in ULL_panel_data is a student, with their academic performance in sixth grade \n",
    "and their predictors of academic performance from third grade (columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'data/'\n",
    "data = pd.read_csv(os.path.join(DATA, 'ULL_panel_data.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_grade</th>\n",
       "      <th>id_student_16_19</th>\n",
       "      <th>score_MAT</th>\n",
       "      <th>level_MAT</th>\n",
       "      <th>score_LEN</th>\n",
       "      <th>level_LEN</th>\n",
       "      <th>id_student</th>\n",
       "      <th>id_student_original</th>\n",
       "      <th>id_year</th>\n",
       "      <th>id_class_group</th>\n",
       "      <th>...</th>\n",
       "      <th>p331a</th>\n",
       "      <th>p331b</th>\n",
       "      <th>p331c</th>\n",
       "      <th>p331d</th>\n",
       "      <th>p331e</th>\n",
       "      <th>p331f</th>\n",
       "      <th>p331g</th>\n",
       "      <th>p331j</th>\n",
       "      <th>pfc</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>474.9944</td>\n",
       "      <td>2</td>\n",
       "      <td>385.1411</td>\n",
       "      <td>1</td>\n",
       "      <td>20342</td>\n",
       "      <td>1431</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>508.8362</td>\n",
       "      <td>3</td>\n",
       "      <td>469.4856</td>\n",
       "      <td>2</td>\n",
       "      <td>2819</td>\n",
       "      <td>1432</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>590.2816</td>\n",
       "      <td>3</td>\n",
       "      <td>591.1398</td>\n",
       "      <td>3</td>\n",
       "      <td>19276</td>\n",
       "      <td>1436</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>394.4247</td>\n",
       "      <td>1</td>\n",
       "      <td>493.7984</td>\n",
       "      <td>2</td>\n",
       "      <td>14078</td>\n",
       "      <td>1439</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>530.0070</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>1695</td>\n",
       "      <td>1447</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15969</th>\n",
       "      <td>6</td>\n",
       "      <td>17267</td>\n",
       "      <td>599.0310</td>\n",
       "      <td>3</td>\n",
       "      <td>615.6177</td>\n",
       "      <td>4</td>\n",
       "      <td>12265</td>\n",
       "      <td>40236</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>6</td>\n",
       "      <td>17268</td>\n",
       "      <td>538.5835</td>\n",
       "      <td>3</td>\n",
       "      <td>647.9100</td>\n",
       "      <td>4</td>\n",
       "      <td>15982</td>\n",
       "      <td>40238</td>\n",
       "      <td>2016</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>6</td>\n",
       "      <td>17269</td>\n",
       "      <td>537.8327</td>\n",
       "      <td>3</td>\n",
       "      <td>445.1313</td>\n",
       "      <td>2</td>\n",
       "      <td>9965</td>\n",
       "      <td>40240</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>6</td>\n",
       "      <td>17270</td>\n",
       "      <td>468.8731</td>\n",
       "      <td>2</td>\n",
       "      <td>546.8035</td>\n",
       "      <td>3</td>\n",
       "      <td>1137</td>\n",
       "      <td>40246</td>\n",
       "      <td>2016</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>6</td>\n",
       "      <td>17271</td>\n",
       "      <td>440.7426</td>\n",
       "      <td>2</td>\n",
       "      <td>471.8504</td>\n",
       "      <td>2</td>\n",
       "      <td>10732</td>\n",
       "      <td>40247</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15974 rows × 565 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_grade  id_student_16_19  score_MAT  level_MAT  score_LEN  level_LEN  \\\n",
       "0             6                 1   474.9944          2   385.1411          1   \n",
       "1             6                 2   508.8362          3   469.4856          2   \n",
       "2             6                 3   590.2816          3   591.1398          3   \n",
       "3             6                 5   394.4247          1   493.7984          2   \n",
       "4             6                 6   530.0070          3   500.0860          3   \n",
       "...         ...               ...        ...        ...        ...        ...   \n",
       "15969         6             17267   599.0310          3   615.6177          4   \n",
       "15970         6             17268   538.5835          3   647.9100          4   \n",
       "15971         6             17269   537.8327          3   445.1313          2   \n",
       "15972         6             17270   468.8731          2   546.8035          3   \n",
       "15973         6             17271   440.7426          2   471.8504          2   \n",
       "\n",
       "       id_student  id_student_original  id_year id_class_group  ...  p331a  \\\n",
       "0           20342                 1431     2016              A  ...    4.0   \n",
       "1            2819                 1432     2016              A  ...    4.0   \n",
       "2           19276                 1436     2016              A  ...    4.0   \n",
       "3           14078                 1439     2016              A  ...    NaN   \n",
       "4            1695                 1447     2016            NaN  ...    NaN   \n",
       "...           ...                  ...      ...            ...  ...    ...   \n",
       "15969       12265                40236     2016              A  ...    4.0   \n",
       "15970       15982                40238     2016              A  ...    4.0   \n",
       "15971        9965                40240     2016            NaN  ...    NaN   \n",
       "15972        1137                40246     2016              B  ...    3.0   \n",
       "15973       10732                40247     2016            NaN  ...    NaN   \n",
       "\n",
       "       p331b  p331c  p331d  p331e  p331f  p331g  p331j  pfc  rep  \n",
       "0        4.0    4.0    4.0    4.0    3.0    NaN    NaN  NaN  NaN  \n",
       "1        NaN    4.0    4.0    3.0    4.0    NaN    NaN  NaN  NaN  \n",
       "2        4.0    4.0    4.0    2.0    4.0    NaN    NaN  NaN  NaN  \n",
       "3        NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "4        NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  ...  ...  \n",
       "15969    NaN    4.0    4.0    4.0    3.0    NaN    NaN  NaN  NaN  \n",
       "15970    NaN    4.0    4.0    4.0    4.0    NaN    NaN  NaN  NaN  \n",
       "15971    NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "15972    4.0    3.0    3.0    3.0    3.0    NaN    NaN  NaN  NaN  \n",
       "15973    NaN    NaN    NaN    NaN    NaN    NaN    NaN  NaN  NaN  \n",
       "\n",
       "[15974 rows x 565 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the data we want to work for\n",
    "data = data[['id_student_16_19', 'score_MAT', 'score_LEN', 'score_MAT3', 'score_LEN3', 'a1',\n",
    "             'mother_education', 'father_education', 'mother_occupation', 'father_occupation', \n",
    "             'inmigrant_second_gen', 'start_schooling_age', 'books', 'f12a', 'public_private', \n",
    "             'capital_island', 'd14', 'ESCS', 'id_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations with missing data in any of the variables that we will use in the models\n",
    "# Here, synthetic data methods can be used instead to fill in missing values\n",
    "\n",
    "missing_columns = ['score_MAT3', 'a1', 'mother_education', 'father_education',\n",
    "    'mother_occupation', 'father_occupation', 'inmigrant_second_gen',\n",
    "    'start_schooling_age', 'books', 'f12a', 'public_private',\n",
    "    'capital_island', 'd14']\n",
    "\n",
    "data = data.dropna(subset=missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_student_16_19</th>\n",
       "      <th>score_MAT</th>\n",
       "      <th>score_LEN</th>\n",
       "      <th>score_MAT3</th>\n",
       "      <th>score_LEN3</th>\n",
       "      <th>a1</th>\n",
       "      <th>mother_education</th>\n",
       "      <th>father_education</th>\n",
       "      <th>mother_occupation</th>\n",
       "      <th>father_occupation</th>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <th>start_schooling_age</th>\n",
       "      <th>books</th>\n",
       "      <th>f12a</th>\n",
       "      <th>public_private</th>\n",
       "      <th>capital_island</th>\n",
       "      <th>d14</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>id_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>530.0070</td>\n",
       "      <td>500.0860</td>\n",
       "      <td>368.65</td>\n",
       "      <td>339.47</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.132756</td>\n",
       "      <td>2443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>531.9280</td>\n",
       "      <td>459.4065</td>\n",
       "      <td>387.36</td>\n",
       "      <td>566.44</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.069410</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>578.3741</td>\n",
       "      <td>630.4484</td>\n",
       "      <td>549.89</td>\n",
       "      <td>635.53</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.166950</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>481.1748</td>\n",
       "      <td>497.1981</td>\n",
       "      <td>592.00</td>\n",
       "      <td>668.26</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976453</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>521.5593</td>\n",
       "      <td>655.0537</td>\n",
       "      <td>490.28</td>\n",
       "      <td>524.98</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.134441</td>\n",
       "      <td>1859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15968</th>\n",
       "      <td>17266</td>\n",
       "      <td>522.6458</td>\n",
       "      <td>611.0034</td>\n",
       "      <td>574.83</td>\n",
       "      <td>591.86</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.759928</td>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15969</th>\n",
       "      <td>17267</td>\n",
       "      <td>599.0310</td>\n",
       "      <td>615.6177</td>\n",
       "      <td>629.84</td>\n",
       "      <td>460.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.410322</td>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>17268</td>\n",
       "      <td>538.5835</td>\n",
       "      <td>647.9100</td>\n",
       "      <td>600.20</td>\n",
       "      <td>542.78</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>17269</td>\n",
       "      <td>537.8327</td>\n",
       "      <td>445.1313</td>\n",
       "      <td>610.26</td>\n",
       "      <td>600.15</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.382896</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>17270</td>\n",
       "      <td>468.8731</td>\n",
       "      <td>546.8035</td>\n",
       "      <td>709.79</td>\n",
       "      <td>557.48</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.787122</td>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8290 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_student_16_19  score_MAT  score_LEN  score_MAT3  score_LEN3  a1  \\\n",
       "4                     6   530.0070   500.0860      368.65      339.47   1   \n",
       "5                     7   531.9280   459.4065      387.36      566.44   1   \n",
       "7                     9   578.3741   630.4484      549.89      635.53   1   \n",
       "8                    10   481.1748   497.1981      592.00      668.26   2   \n",
       "11                   13   521.5593   655.0537      490.28      524.98   2   \n",
       "...                 ...        ...        ...         ...         ...  ..   \n",
       "15968             17266   522.6458   611.0034      574.83      591.86   1   \n",
       "15969             17267   599.0310   615.6177      629.84      460.75   1   \n",
       "15970             17268   538.5835   647.9100      600.20      542.78   1   \n",
       "15971             17269   537.8327   445.1313      610.26      600.15   2   \n",
       "15972             17270   468.8731   546.8035      709.79      557.48   2   \n",
       "\n",
       "       mother_education  father_education  mother_occupation  \\\n",
       "4                   3.0               1.0                4.0   \n",
       "5                   4.0               4.0                4.0   \n",
       "7                   2.0               2.0                3.0   \n",
       "8                   4.0               4.0                4.0   \n",
       "11                  4.0               4.0                3.0   \n",
       "...                 ...               ...                ...   \n",
       "15968               4.0               3.0                3.0   \n",
       "15969               4.0               3.0                4.0   \n",
       "15970               4.0               2.0                3.0   \n",
       "15971               4.0               1.0                3.0   \n",
       "15972               4.0               2.0                3.0   \n",
       "\n",
       "       father_occupation  inmigrant_second_gen  start_schooling_age  books  \\\n",
       "4                    2.0                   1.0                  1.0    1.0   \n",
       "5                    3.0                   1.0                  1.0    4.0   \n",
       "7                    2.0                   1.0                  2.0    2.0   \n",
       "8                    4.0                   1.0                  1.0    3.0   \n",
       "11                   3.0                   1.0                  1.0    2.0   \n",
       "...                  ...                   ...                  ...    ...   \n",
       "15968                3.0                   1.0                  1.0    4.0   \n",
       "15969                3.0                   1.0                  1.0    4.0   \n",
       "15970                3.0                   1.0                  1.0    2.0   \n",
       "15971                3.0                   1.0                  1.0    3.0   \n",
       "15972                3.0                   1.0                  2.0    4.0   \n",
       "\n",
       "       f12a  public_private  capital_island  d14      ESCS  id_school  \n",
       "4       1.0               2               2  4.0  0.132756       2443  \n",
       "5       5.0               2               1  1.0  1.069410       1368  \n",
       "7       2.0               2               1  1.0 -1.166950       2500  \n",
       "8       4.0               1               1  1.0  0.976453       1610  \n",
       "11      5.0               2               1  1.0 -0.134441       1859  \n",
       "...     ...             ...             ...  ...       ...        ...  \n",
       "15968   2.0               2               1  2.0  0.759928       2413  \n",
       "15969   2.0               2               1  2.0  1.410322       2203  \n",
       "15970   3.0               2               1  2.0  0.035227       2095  \n",
       "15971   2.0               2               1  2.0  0.382896       2097  \n",
       "15972   5.0               2               1  4.0  0.787122       2364  \n",
       "\n",
       "[8290 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.columns \n",
    "data = pd.DataFrame(data.values.flatten().reshape(-1, data.shape[1]), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate quartiles of scores in sixth grade\n",
    "data['scores_MATq'] = pd.qcut(data['score_MAT'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['scores_MATq'] = data['scores_MATq'].astype(int)\n",
    "data['scores_LENq'] = pd.qcut(data['score_LEN'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['scores_LENq'] = data['scores_LENq'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate median and percentiles 25 and 75 of socioeconomic status (ESCS)\n",
    "median_ESCS = data['ESCS'].median()\n",
    "p25_ESCS = data['ESCS'].quantile(0.25)\n",
    "p75_ESCS = data['ESCS'].quantile(0.75)\n",
    "\n",
    "# Initialize with null values\n",
    "data['ESCS_median'] = pd.Series([np.nan] * len(data))\n",
    "data.loc[data['ESCS'] >= median_ESCS, 'ESCS_median'] = 2\n",
    "data.loc[data['ESCS'] < median_ESCS, 'ESCS_median'] = 1\n",
    "data.loc[data['ESCS_median'] == 0, 'ESCS_median'] = np.nan\n",
    "\n",
    "# Initialize with null values\n",
    "data['ESCS_p25_p75'] = pd.Series([np.nan] * len(data))\n",
    "data.loc[data['ESCS'] >= p75_ESCS, 'ESCS_p25_p75'] = 2\n",
    "data.loc[data['ESCS'] < p25_ESCS, 'ESCS_p25_p75'] = 1\n",
    "data.loc[(data['ESCS'] >= p25_ESCS) & (data['ESCS'] < p75_ESCS), 'ESCS_p25_p75'] = np.nan\n",
    "\n",
    "# Some data corrections to make the final results\n",
    "# Variable d14 top category(4) is the \"bad\" category (more than 50% of teachers change school), so the results must be inverted\n",
    "# isn't this applying the identity?\n",
    "data['d14'] = data['d14'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "The goal of the model is to predict the academic performance in sixth grade ($Y_t$)\n",
    "using information from the same student in third grade, specifically:\n",
    "\n",
    "1.  Academic performance in third grade ($Y_{t-1}$)\n",
    "\n",
    "2.  Sensitive factors or circumstances ($C$)\n",
    "\n",
    "3.  Predictors uncorrelated with circumstances, also called \"effort\" ($X$)\n",
    "\n",
    "**Model 1**:    $$Y_t = α + β1Y_{t-1} + ε$$\n",
    "\n",
    "**Model 2**:    $$Y_t = α + β1Y_{t-1} + β2C + ε$$\n",
    "\n",
    "**Model 3**:    \n",
    "\n",
    "> First step: $$Y_{t-1} = α + β2C + ν$$\n",
    "\n",
    "- Recover the prediction of $Y_{t-1}$ (academic performance due to circumstances, $C$): $\\hat{Y}_{t-1}$\n",
    "\n",
    "- Recover the residual $ν$ (academic performance due to effort, $X$): $\\hat{ν}$\n",
    "\n",
    "> Second step: $$Y_t = α + β1\\hat{Y}_{t-1} + β2\\hat{ν} + ε$$\n",
    "\n",
    "- Recover the prediction of $Y_t$ only due to $\\hat{Y}_{t-1}$ (only due to circumstances)\n",
    "\n",
    "- Recover the prediction of $Y_t$ only due to $\\hat{ν}$ (only due to effort)\n",
    "\n",
    "In theory...\n",
    "\n",
    "**Model 1**: Using only the academic performance in third grade (benchmark)\n",
    "\n",
    "**Model 2**: Using the academic performance + circumstances in third grade (less fair - more socially desirable)\n",
    "\n",
    "**Model 3**: Using the circumstances + effort in third grade (close to Model 2)\n",
    "\n",
    "- Prediction exclusively of circumstances of Model 3 (much less fair - much more socially desirable)\n",
    "    \n",
    "- Prediction exclusively of effort of Model 3 (much more fair - much less socially desirable)\n",
    "\n",
    "Let's prove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for the models\n",
    "Y_t_1 = \"score_MAT3\"\n",
    "c = data[[\"a1\", \"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \n",
    "      \"inmigrant_second_gen\", \"start_schooling_age\", \"books\", \"f12a\", \"public_private\", \"capital_island\", \"d14\"]]\n",
    "circumstances = [\"a1\", \"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \n",
    "      \"inmigrant_second_gen\", \"start_schooling_age\", \"books\", \"f12a\", \"public_private\", \"capital_island\", \"d14\"]\n",
    "\n",
    "# Dummy variables (all variables C are categorical variables)\n",
    "dummy_variables = pd.get_dummies(c, columns=circumstances, drop_first = True)\n",
    "\n",
    "# Join Y_t_1 + C\n",
    "data_combined = pd.concat([data[Y_t_1], dummy_variables], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              score_MAT   R-squared:                       0.253\n",
      "Model:                            OLS   Adj. R-squared:                  0.253\n",
      "Method:                 Least Squares   F-statistic:                     2810.\n",
      "Date:                Fri, 12 Jul 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:58:09   Log-Likelihood:                -48733.\n",
      "No. Observations:                8290   AIC:                         9.747e+04\n",
      "Df Residuals:                    8288   BIC:                         9.748e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        232.0412      5.403     42.946      0.000     221.450     242.632\n",
      "score_MAT3     0.5405      0.010     53.009      0.000       0.520       0.560\n",
      "==============================================================================\n",
      "Omnibus:                       28.433   Durbin-Watson:                   2.041\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.356\n",
      "Skew:                           0.125   Prob(JB):                     4.22e-07\n",
      "Kurtosis:                       3.149   Cond. No.                     3.02e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.02e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "model1 = sm.OLS(data[\"score_MAT\"], sm.add_constant(data[Y_t_1])).fit()\n",
    "print(model1.summary())\n",
    "data['model1_pred'] = model1.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              score_MAT   R-squared:                       0.270\n",
      "Model:                            OLS   Adj. R-squared:                  0.267\n",
      "Method:                 Least Squares   F-statistic:                     112.9\n",
      "Date:                Fri, 12 Jul 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:58:09   Log-Likelihood:                -48641.\n",
      "No. Observations:                8290   AIC:                         9.734e+04\n",
      "Df Residuals:                    8262   BIC:                         9.754e+04\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                      233.7944     17.481     13.374      0.000     199.527     268.062\n",
      "score_MAT3                   0.5034      0.011     47.475      0.000       0.483       0.524\n",
      "a1_2.0                      -2.8025      1.886     -1.486      0.137      -6.499       0.894\n",
      "mother_education_2.0        -2.3669      3.954     -0.599      0.550     -10.119       5.385\n",
      "mother_education_3.0         0.8173      4.039      0.202      0.840      -7.101       8.735\n",
      "mother_education_4.0         4.4566      4.112      1.084      0.278      -3.603      12.516\n",
      "father_education_2.0         8.7789      3.197      2.746      0.006       2.513      15.045\n",
      "father_education_3.0        10.9882      3.309      3.320      0.001       4.501      17.475\n",
      "father_education_4.0        23.2528      3.482      6.679      0.000      16.428      30.078\n",
      "mother_occupation_2.0       -6.2343      7.414     -0.841      0.400     -20.768       8.299\n",
      "mother_occupation_3.0       -7.3676      7.149     -1.031      0.303     -21.381       6.646\n",
      "mother_occupation_4.0       -7.9740      7.386     -1.080      0.280     -22.453       6.505\n",
      "father_occupation_2.0        2.7770     15.961      0.174      0.862     -28.511      34.065\n",
      "father_occupation_3.0        3.7053     15.828      0.234      0.815     -27.322      34.733\n",
      "father_occupation_4.0        5.6010     15.925      0.352      0.725     -25.616      36.818\n",
      "inmigrant_second_gen_2.0     3.5585      3.846      0.925      0.355      -3.980      11.097\n",
      "start_schooling_age_2.0     -4.2066      2.128     -1.977      0.048      -8.378      -0.035\n",
      "start_schooling_age_3.0    -10.7953      6.863     -1.573      0.116     -24.248       2.658\n",
      "books_2.0                    8.1626      3.154      2.588      0.010       1.981      14.344\n",
      "books_3.0                   12.6814      3.533      3.589      0.000       5.755      19.607\n",
      "books_4.0                   17.7128      3.826      4.629      0.000      10.212      25.213\n",
      "f12a_2.0                    -1.8582      4.321     -0.430      0.667     -10.328       6.612\n",
      "f12a_3.0                    -3.7246      6.724     -0.554      0.580     -16.905       9.456\n",
      "f12a_4.0                    -0.7653      4.695     -0.163      0.871      -9.968       8.437\n",
      "f12a_5.0                    -3.5088      4.406     -0.796      0.426     -12.146       5.129\n",
      "public_private_2.0           1.0242      2.699      0.379      0.704      -4.267       6.315\n",
      "capital_island_2.0           3.3137      2.810      1.179      0.238      -2.195       8.822\n",
      "d14_1                       -1.9338      2.364     -0.818      0.413      -6.568       2.701\n",
      "==============================================================================\n",
      "Omnibus:                       34.304   Durbin-Watson:                   2.035\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.747\n",
      "Skew:                           0.136   Prob(JB):                     1.73e-08\n",
      "Kurtosis:                       3.171   Cond. No.                     1.76e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.76e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "model2 = sm.OLS(data[\"score_MAT\"], sm.add_constant(data_combined.astype(np.float64))).fit()\n",
    "print(model2.summary())\n",
    "data['model2_pred'] = model2.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             score_MAT3   R-squared:                       0.093\n",
      "Model:                            OLS   Adj. R-squared:                  0.090\n",
      "Method:                 Least Squares   F-statistic:                     32.51\n",
      "Date:                Fri, 12 Jul 2024   Prob (F-statistic):          3.71e-153\n",
      "Time:                        14:58:09   Log-Likelihood:                -48947.\n",
      "No. Observations:                8290   AIC:                         9.795e+04\n",
      "Df Residuals:                    8263   BIC:                         9.814e+04\n",
      "Df Model:                          26                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                      456.2769     17.428     26.180      0.000     422.113     490.441\n",
      "a1_2.0                      -5.5566      1.955     -2.842      0.004      -9.389      -1.724\n",
      "mother_education_2.0        10.1833      4.101      2.483      0.013       2.144      18.223\n",
      "mother_education_3.0        18.2461      4.186      4.359      0.000      10.041      26.452\n",
      "mother_education_4.0        30.1625      4.253      7.092      0.000      21.826      38.499\n",
      "father_education_2.0         8.1520      3.315      2.459      0.014       1.653      14.651\n",
      "father_education_3.0        16.7990      3.428      4.900      0.000      10.079      23.519\n",
      "father_education_4.0        28.6703      3.598      7.968      0.000      21.617      35.724\n",
      "mother_occupation_2.0       19.7715      7.689      2.571      0.010       4.699      34.844\n",
      "mother_occupation_3.0       20.0692      7.414      2.707      0.007       5.537      34.602\n",
      "mother_occupation_4.0       23.6740      7.659      3.091      0.002       8.661      38.687\n",
      "father_occupation_2.0      -17.4934     16.559     -1.056      0.291     -49.952      14.966\n",
      "father_occupation_3.0      -15.1249     16.421     -0.921      0.357     -47.314      17.065\n",
      "father_occupation_4.0      -13.7633     16.521     -0.833      0.405     -46.149      18.622\n",
      "inmigrant_second_gen_2.0    -3.0461      3.990     -0.763      0.445     -10.867       4.775\n",
      "start_schooling_age_2.0     -3.1587      2.208     -1.431      0.153      -7.487       1.169\n",
      "start_schooling_age_3.0     -7.9188      7.120     -1.112      0.266     -21.875       6.038\n",
      "books_2.0                   13.7782      3.268      4.216      0.000       7.372      20.185\n",
      "books_3.0                   25.3228      3.655      6.928      0.000      18.158      32.488\n",
      "books_4.0                   35.6318      3.950      9.020      0.000      27.888      43.375\n",
      "f12a_2.0                     5.6883      4.482      1.269      0.204      -3.098      14.475\n",
      "f12a_3.0                    18.6752      6.973      2.678      0.007       5.007      32.344\n",
      "f12a_4.0                     7.3650      4.870      1.512      0.130      -2.181      16.911\n",
      "f12a_5.0                     1.0154      4.572      0.222      0.824      -7.946       9.977\n",
      "public_private_2.0           2.3481      2.800      0.839      0.402      -3.141       7.837\n",
      "capital_island_2.0         -14.1954      2.911     -4.876      0.000     -19.902      -8.489\n",
      "d14_1                       10.3961      2.450      4.243      0.000       5.593      15.199\n",
      "==============================================================================\n",
      "Omnibus:                      108.881   Durbin-Watson:                   1.974\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               66.123\n",
      "Skew:                           0.029   Prob(JB):                     4.38e-15\n",
      "Kurtosis:                       2.566   Cond. No.                         67.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              score_MAT   R-squared:                       0.265\n",
      "Model:                            OLS   Adj. R-squared:                  0.265\n",
      "Method:                 Least Squares   F-statistic:                     1493.\n",
      "Date:                Fri, 12 Jul 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:58:09   Log-Likelihood:                -48668.\n",
      "No. Observations:                8290   AIC:                         9.734e+04\n",
      "Df Residuals:                    8287   BIC:                         9.736e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         43.0305     17.349      2.480      0.013       9.022      77.039\n",
      "Y_t_1_hat      0.9028      0.033     27.186      0.000       0.838       0.968\n",
      "ν_hat          0.5034      0.011     47.395      0.000       0.483       0.524\n",
      "==============================================================================\n",
      "Omnibus:                       34.929   Durbin-Watson:                   2.037\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.672\n",
      "Skew:                           0.135   Prob(JB):                     1.09e-08\n",
      "Kurtosis:                       3.183   Cond. No.                     9.62e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.62e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "model3 = sm.OLS(data[\"score_MAT3\"], sm.add_constant(dummy_variables.astype(np.float64))).fit()\n",
    "print(model3.summary())\n",
    "\n",
    "# First step\n",
    "data['Y_t_1_hat'] = model3.fittedvalues\n",
    "data['ν_hat'] = model3.resid\n",
    "\n",
    "# Second step\n",
    "model4 = sm.OLS(data[\"score_MAT\"], sm.add_constant(data[[\"Y_t_1_hat\", \"ν_hat\"]])).fit()\n",
    "print(model4.summary())\n",
    "data['model3_pred'] = model3.fittedvalues\n",
    "\n",
    "# Prediction exclusively of circumstances\n",
    "data['model3_pred_circum'] = model4.params['const'] + model4.params['Y_t_1_hat'] * data['Y_t_1_hat']\n",
    "# Prediction exclusively of effort\n",
    "mean_circu = data['Y_t_1_hat'].mean()\n",
    "data['mean_circu'] = mean_circu\n",
    "data['model3_pred_effort'] = (model4.params['const'] + \n",
    "                          model4.params['ν_hat'] * data['ν_hat'] + \n",
    "                          model4.params['Y_t_1_hat'] * mean_circu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform predictions(continuous) to quartiles(categorical)\n",
    "\n",
    "data['scores_MAT_pred1'] = pd.qcut(data['model1_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['scores_MAT_pred1'] = data['scores_MAT_pred1'].astype(int)\n",
    "data['scores_MAT_pred2'] = pd.qcut(data['model2_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['scores_MAT_pred2'] = data['scores_MAT_pred2'].astype(int)\n",
    "data['scores_MAT_pred3'] = pd.qcut(data['model3_pred'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['scores_MAT_pred3'] = data['scores_MAT_pred3'].astype(int)\n",
    "data['scores_MAT_pred_C'] = pd.qcut(data['model3_pred_circum'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['scores_MAT_pred_C'] = data['scores_MAT_pred_C'].astype(int)\n",
    "data['scores_MAT_pred_X'] = pd.qcut(data['model3_pred_effort'], 4, labels=[\"1\", \"2\", \"3\",\"4\"])\n",
    "data['scores_MAT_pred_X'] = data['scores_MAT_pred_X'].astype(int)\n",
    "\n",
    "# Transform predictions(continuous) to percentiles but percentiles 2 and 3 equal (between 25th and 75th percentile)\n",
    "\n",
    "data['scores_MAT_pred1_t'] = data['scores_MAT_pred1'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "data['scores_MAT_pred2_t'] = data['scores_MAT_pred2'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "data['scores_MAT_pred3_t'] = data['scores_MAT_pred3'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "data['scores_MAT_pred_C_t'] = data['scores_MAT_pred_C'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))\n",
    "data['scores_MAT_pred_X_t'] = data['scores_MAT_pred_X'].apply(lambda x: 1 if x == 1 else (2 if x == 2 or x == 3 else 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on **Equalized Odds** (Equality of opportunity).\n",
    "\n",
    "To calculate Equalized Odds we first calculate recall or sensitivity:\n",
    "\n",
    "$$TP / (TP + FN)$$\n",
    "\n",
    "and then we calculate the ratio of recall among different groups to obtain Equalized Odds.\n",
    "\n",
    "Recall is calculated for Low and High academic performance:\n",
    "- **Low academic performance**: Below the median or 25th percentile\n",
    "- **High academic performance**: Above the median or above 75th percentile (top 25 percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_dfs_25_75 = []\n",
    "recall_dfs_25_75.extend(compute_recall(data, [\"f12a\"], top_level=5))\n",
    "recall_dfs_25_75.extend(compute_recall(data, [\"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \"books\"], top_level=4))\n",
    "recall_dfs_25_75.extend(compute_recall(data, [\"start_schooling_age\"], top_level=1))\n",
    "recall_dfs_25_75.extend(compute_recall(data, [\"inmigrant_second_gen\", \"public_private\", \"capital_island\", \"a1\", \"ESCS_median\", \"ESCS_p25_p75\", \"d14\"], top_level=1))\n",
    "\n",
    "recall_dfs_between25_75 = []\n",
    "recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"f12a\"], top_level=5))\n",
    "recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \"books\"], top_level=4))\n",
    "recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"start_schooling_age\"], top_level=1))\n",
    "recall_dfs_between25_75.extend(compute_recall_terciles(data, [\"inmigrant_second_gen\", \"public_private\", \"capital_island\", \"a1\", \"ESCS_median\", \"ESCS_p25_p75\", \"d14\"], top_level=1))\n",
    "\n",
    "recall_dfs_median = []\n",
    "recall_dfs_median.extend(compute_recall_median(data, [\"f12a\"], top_level=5))\n",
    "recall_dfs_median.extend(compute_recall_median(data, [\"mother_education\", \"father_education\", \"mother_occupation\", \"father_occupation\", \"books\"], top_level=4))\n",
    "recall_dfs_median.extend(compute_recall_median(data, [\"start_schooling_age\"], top_level=1))\n",
    "recall_dfs_median.extend(compute_recall_median(data, [\"inmigrant_second_gen\", \"public_private\", \"capital_island\", \"a1\", \"ESCS_median\", \"ESCS_p25_p75\", \"d14\"], top_level=1))\n",
    "\n",
    "# Combine DataFrames\n",
    "combined_df_25_75 = pd.concat(recall_dfs_25_75, ignore_index=True)\n",
    "combined_df_between25_75 = pd.concat(recall_dfs_between25_75, ignore_index=True)\n",
    "combined_df_median = pd.concat(recall_dfs_median, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tables\n",
    "pivot_combined_df_25_75 = combined_df_25_75.pivot_table(index=['Variable', 'Group', 'Percentile'], columns='Model', values='Recall').reset_index()\n",
    "pivot_combined_df_25_75 = pivot_combined_df_25_75[['Variable', 'Group', 'Percentile', 'pred1', 'pred2', 'pred3', 'pred_C', 'pred_X']]\n",
    "pivot_combined_df_25_75_sorted = pivot_combined_df_25_75.sort_values(by=['Percentile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "pivot_combined_df_between25_75 = combined_df_between25_75.pivot_table(index=['Variable', 'Group', 'Tercile'], columns='Model', values='Recall').reset_index()\n",
    "pivot_combined_df_between25_75 = pivot_combined_df_between25_75[['Variable', 'Group', 'Tercile', 'pred1_t', 'pred2_t', 'pred3_t', 'pred_C_t', 'pred_X_t']]\n",
    "pivot_combined_df_between25_75_sorted = pivot_combined_df_between25_75.sort_values(by=['Tercile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "pivot_combined_df_median = combined_df_median.pivot_table(index=['Variable', 'Group', 'Pair1', 'Pair2'], columns='Model', values='Recall').reset_index()\n",
    "pivot_combined_df_median = pivot_combined_df_median[['Variable', 'Group', 'Pair1', 'Pair2', 'pred1', 'pred2', 'pred3', 'pred_C', 'pred_X']]\n",
    "pivot_combined_df_median_sorted = pivot_combined_df_median.sort_values(by=['Pair1', 'Pair2', 'Variable', 'Group'], ascending=[True, True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_25_75 = []\n",
    "\n",
    "for variable in pivot_combined_df_25_75_sorted['Variable'].unique():\n",
    "    variable_df = pivot_combined_df_25_75_sorted[pivot_combined_df_25_75_sorted['Variable'] == variable]\n",
    "    for percentile in variable_df['Percentile'].unique():\n",
    "        top_row = variable_df[(variable_df['Group'] == 'top') & (variable_df['Percentile'] == percentile)]\n",
    "        if not top_row.empty:\n",
    "            top_row = top_row.iloc[0]\n",
    "            temp_data = []\n",
    "            for _, row in variable_df[variable_df['Percentile'] == percentile].iterrows():\n",
    "                odds_row = {\n",
    "                    'Variable': row['Variable'],\n",
    "                    'Group': row['Group'],\n",
    "                    'Percentile': row['Percentile'],\n",
    "                    'pred1': row['pred1'],\n",
    "                    'pred2': row['pred2'],\n",
    "                    'pred3': row['pred3'],\n",
    "                    'pred_C': row['pred_C'],\n",
    "                    'pred_X': row['pred_X'],\n",
    "                    'pred1_odds': calculate_odds(row['pred1'], top_row['pred1']),\n",
    "                    'pred2_odds': calculate_odds(row['pred2'], top_row['pred2']),\n",
    "                    'pred3_odds': calculate_odds(row['pred3'], top_row['pred3']),\n",
    "                    'pred_C_odds': calculate_odds(row['pred_C'], top_row['pred_C']),\n",
    "                    'pred_X_odds': calculate_odds(row['pred_X'], top_row['pred_X']),\n",
    "                }\n",
    "                temp_data.append(odds_row)\n",
    "            final_data_25_75.extend(temp_data)\n",
    "\n",
    "final_data_25_75_sorted = pd.DataFrame(final_data_25_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_between25_75 = []\n",
    "\n",
    "for variable in pivot_combined_df_between25_75_sorted['Variable'].unique():\n",
    "    variable_df = pivot_combined_df_between25_75_sorted[pivot_combined_df_between25_75_sorted['Variable'] == variable]\n",
    "    for tercile in variable_df['Tercile'].unique():\n",
    "        top_row = variable_df[(variable_df['Group'] == 'top') & (variable_df['Tercile'] == tercile)]\n",
    "        if not top_row.empty:\n",
    "            top_row = top_row.iloc[0]\n",
    "            temp_data = []\n",
    "            for _, row in variable_df[variable_df['Tercile'] == tercile].iterrows():\n",
    "                odds_row = {\n",
    "                    'Variable': row['Variable'],\n",
    "                    'Group': row['Group'],\n",
    "                    'Tercile': row['Tercile'],\n",
    "                    'pred1_t': row['pred1_t'],\n",
    "                    'pred2_t': row['pred2_t'],\n",
    "                    'pred3_t': row['pred3_t'],\n",
    "                    'pred_C_t': row['pred_C_t'],\n",
    "                    'pred_X_t': row['pred_X_t'],\n",
    "                    'pred1_odds': calculate_odds(row['pred1_t'], top_row['pred1_t']),\n",
    "                    'pred2_odds': calculate_odds(row['pred2_t'], top_row['pred2_t']),\n",
    "                    'pred3_odds': calculate_odds(row['pred3_t'], top_row['pred3_t']),\n",
    "                    'pred_C_odds': calculate_odds(row['pred_C_t'], top_row['pred_C_t']),\n",
    "                    'pred_X_odds': calculate_odds(row['pred_X_t'], top_row['pred_X_t']),\n",
    "                }\n",
    "                temp_data.append(odds_row)\n",
    "            final_data_between25_75.extend(temp_data)\n",
    "\n",
    "final_data_between25_75_sorted = pd.DataFrame(final_data_between25_75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_median = []\n",
    "\n",
    "for variable in pivot_combined_df_median_sorted['Variable'].unique():\n",
    "    variable_df = pivot_combined_df_median_sorted[pivot_combined_df_median_sorted['Variable'] == variable]\n",
    "    for pair in variable_df[['Pair1', 'Pair2']].drop_duplicates().values:\n",
    "        pair1, pair2 = pair\n",
    "        top_row = variable_df[(variable_df['Group'] == 'top') & (variable_df['Pair1'] == pair1) & (variable_df['Pair2'] == pair2)]\n",
    "        if not top_row.empty:\n",
    "            top_row = top_row.iloc[0]\n",
    "            temp_data = []\n",
    "            for _, row in variable_df[(variable_df['Pair1'] == pair1) & (variable_df['Pair2'] == pair2)].iterrows():\n",
    "                odds_row = {\n",
    "                    'Variable': row['Variable'],\n",
    "                    'Group': row['Group'],\n",
    "                    'Pair1': row['Pair1'],\n",
    "                    'Pair2': row['Pair2'],\n",
    "                    'pred1': row['pred1'],\n",
    "                    'pred2': row['pred2'],\n",
    "                    'pred3': row['pred3'],\n",
    "                    'pred_C': row['pred_C'],\n",
    "                    'pred_X': row['pred_X'],\n",
    "                    'pred1_odds': calculate_odds(row['pred1'], top_row['pred1']),\n",
    "                    'pred2_odds': calculate_odds(row['pred2'], top_row['pred2']),\n",
    "                    'pred3_odds': calculate_odds(row['pred3'], top_row['pred3']),\n",
    "                    'pred_C_odds': calculate_odds(row['pred_C'], top_row['pred_C']),\n",
    "                    'pred_X_odds': calculate_odds(row['pred_X'], top_row['pred_X']),\n",
    "                }\n",
    "                temp_data.append(odds_row)\n",
    "            final_data_median.extend(temp_data)\n",
    "\n",
    "final_data_median_sorted = pd.DataFrame(final_data_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = ['a1', 'mother_education', 'father_education', 'mother_occupation', 'father_occupation', 'books', 'd14', 'inmigrant_second_gen', \n",
    "                  'public_private', 'capital_island', 'start_schooling_age', 'f12a', 'ESCS_median', 'ESCS_p25_p75']\n",
    "\n",
    "final_data_25_75_sorted['Variable'] = pd.Categorical(final_data_25_75_sorted['Variable'], categories=category_order, ordered=True)\n",
    "final_data_25_75_sorted = final_data_25_75_sorted.sort_values(by='Variable')\n",
    "final_data_25_75_sorted = final_data_25_75_sorted[['Variable', 'Group', 'Percentile', 'pred1', 'pred1_odds', 'pred2', 'pred2_odds', 'pred3', 'pred3_odds', 'pred_C', 'pred_C_odds', 'pred_X', 'pred_X_odds']]\n",
    "final_data_25_75_sorted = final_data_25_75_sorted.sort_values(by=['Percentile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "final_data_between25_75_sorted['Variable'] = pd.Categorical(final_data_between25_75_sorted['Variable'], categories=category_order, ordered=True)\n",
    "final_data_between25_75_sorted = final_data_between25_75_sorted.sort_values(by='Variable')\n",
    "final_data_between25_75_sorted = final_data_between25_75_sorted[['Variable', 'Group', 'Tercile', 'pred1_t', 'pred1_odds', 'pred2_t', 'pred2_odds', 'pred3_t', 'pred3_odds', 'pred_C_t', 'pred_C_odds', 'pred_X_t', 'pred_X_odds']]\n",
    "final_data_between25_75_sorted = final_data_between25_75_sorted.sort_values(by=['Tercile', 'Variable', 'Group'], ascending=[True, True, False])\n",
    "final_data_median_sorted['Variable'] = pd.Categorical(final_data_median_sorted['Variable'], categories=category_order, ordered=True)\n",
    "final_data_median_sorted = final_data_median_sorted.sort_values(by='Variable')\n",
    "final_data_median_sorted = final_data_median_sorted[['Variable', 'Group', 'Pair1', 'Pair2', 'pred1', 'pred1_odds', 'pred2', 'pred2_odds', 'pred3', 'pred3_odds', 'pred_C', 'pred_C_odds', 'pred_X', 'pred_X_odds']]\n",
    "final_data_median_sorted = final_data_median_sorted.sort_values(by=['Pair1', 'Pair2', 'Variable', 'Group'], ascending=[True, True, True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel\n",
    "with pd.ExcelWriter(os.path.join('results', 'results.xlsx')) as writer:\n",
    "    final_data_25_75_sorted.to_excel(writer, sheet_name='25_75', index=False, float_format='%.4f')\n",
    "    final_data_median_sorted.to_excel(writer, sheet_name='Median', index=False, float_format='%.4f')\n",
    "    final_data_between25_75_sorted.to_excel(writer, sheet_name='between25_75', index=False, float_format='%.4f')\n",
    "    data.to_excel(writer, sheet_name='data', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOP\n",
    "\n",
    "Inequality of Opportunity is computed by applying an inequality index (Gini, MLD or simple variance) to the set of central moments (specifically, the mean $\\mu$) for the $Y$'s conditional distributions with respect to a sensitive attribute's values. Mathematically:\n",
    "$$IOP = I(\\mu(Y|G_{i}), \\ldots, \\mu(Y|G_{m}))$$ \n",
    "\n",
    "$I$ is the inequality index while $G_{1} \\ldots G_{m}$ are the $m$ different groups of individuals identified by the values a given senstive attribute can have. For example, if _gender_ is a sensitive attribute then the two resulting groups might be $G_{1} = male$ and $G_{2} = female$. In this situation, _IOP_ would be absent if $$I(\\mu(Y|G_{1}),\\mu(Y|G_{2})) = 0$$ or close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_student_16_19', 'score_MAT', 'score_LEN', 'score_MAT3',\n",
       "       'score_LEN3', 'a1', 'mother_education', 'father_education',\n",
       "       'mother_occupation', 'father_occupation', 'inmigrant_second_gen',\n",
       "       'start_schooling_age', 'books', 'f12a', 'public_private',\n",
       "       'capital_island', 'd14', 'ESCS', 'id_school', 'scores_MATq',\n",
       "       'scores_LENq', 'ESCS_median', 'ESCS_p25_p75', 'model1_pred',\n",
       "       'model2_pred', 'Y_t_1_hat', 'ν_hat', 'model3_pred',\n",
       "       'model3_pred_circum', 'mean_circu', 'model3_pred_effort',\n",
       "       'scores_MAT_pred1', 'scores_MAT_pred2', 'scores_MAT_pred3',\n",
       "       'scores_MAT_pred_C', 'scores_MAT_pred_X', 'scores_MAT_pred1_t',\n",
       "       'scores_MAT_pred2_t', 'scores_MAT_pred3_t', 'scores_MAT_pred_C_t',\n",
       "       'scores_MAT_pred_X_t'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(data, percentile, ineq_index):\n",
    "    sensitive_attrs = ['a1', 'mother_education', 'father_education',\n",
    "       'mother_occupation', 'father_occupation', 'inmigrant_second_gen',\n",
    "       'start_schooling_age', 'books', 'f12a', 'public_private',\n",
    "       'capital_island', 'd14', \"ESCS_median\", \"ESCS_p25_p75\"]\n",
    "\n",
    "    model_preds = [\"model1_pred\", \"model2_pred\", \"model3_pred\", \"model3_pred_circum\", \"model3_pred_effort\"]\n",
    "\n",
    "    model_pred_rename = {\n",
    "        \"model1_pred\": \"Model 1\",\n",
    "        \"model2_pred\": \"Model 2\",\n",
    "        \"model3_pred\": \"Model 3\",\n",
    "        \"model3_pred_circum\": \"Circumstances\",\n",
    "        \"model3_pred_effort\": \"Effort\"\n",
    "    }\n",
    "\n",
    "    df = {}\n",
    "    for mp in model_preds:\n",
    "        col = []\n",
    "        data[\"label\"] = binarise_predictions(data[mp], percentile)\n",
    "        for sa in sensitive_attrs:\n",
    "            col.append(iop(data, sa, ineq_index=ineq_index))\n",
    "        df[model_pred_rename[mp]] = col\n",
    "\n",
    "    return pd.DataFrame(df, index=sensitive_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/liamjames/liam/phd/AEQUITAS/ULL/metric/aaai_24/code/experiments.ipynb Cell 34\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamjames/liam/phd/AEQUITAS/ULL/metric/aaai_24/code/experiments.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamjames/liam/phd/AEQUITAS/ULL/metric/aaai_24/code/experiments.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# below 25th percentile\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/liamjames/liam/phd/AEQUITAS/ULL/metric/aaai_24/code/experiments.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m pred \u001b[39min\u001b[39;00m preds:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamjames/liam/phd/AEQUITAS/ULL/metric/aaai_24/code/experiments.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     data[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m binarise_predictions(data[pred], \u001b[39m\"\u001b[39m\u001b[39mbelow-25\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamjames/liam/phd/AEQUITAS/ULL/metric/aaai_24/code/experiments.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m sa \u001b[39min\u001b[39;00m sensitive_attrs:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# below 25th percentile\n",
    "\n",
    "for pred in preds:\n",
    "    data[\"label\"] = binarise_predictions(data[pred], \"below-25\")\n",
    "    for sa in sensitive_attrs:\n",
    "        sensitive_vals = np.unique(data[sa].values[~np.isnan(data[sa].values)])\n",
    "        fig, ax = plt.subplots(1, len(sensitive_vals), figsize=(20, 4))\n",
    "        for idx, sv in enumerate(sensitive_vals):\n",
    "            counts = data.loc[(data[sa] == sv)].label.value_counts()\n",
    "            if len(counts) > 0:\n",
    "                ax[idx].set_title(f\"{model_pred_rename[pred]}, {sa} = {sv}\")\n",
    "                plot = counts.sort_values().plot(kind='barh', ax=ax[idx])\n",
    "                ax[idx].set_xlabel(\"counts\")\n",
    "                ax[idx].set_ylabel(\"labels\")\n",
    "            else:\n",
    "                print(f\"No samples for {sa} = {sv}\")\n",
    "        fig.suptitle(\"Predictions below 25th percentile\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below 25th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.034491</td>\n",
       "      <td>0.072254</td>\n",
       "      <td>0.072254</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>0.147250</td>\n",
       "      <td>0.132537</td>\n",
       "      <td>0.337668</td>\n",
       "      <td>0.337668</td>\n",
       "      <td>0.306198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.199831</td>\n",
       "      <td>0.368014</td>\n",
       "      <td>0.368014</td>\n",
       "      <td>0.161480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>0.418354</td>\n",
       "      <td>0.409912</td>\n",
       "      <td>0.377166</td>\n",
       "      <td>0.377166</td>\n",
       "      <td>0.458392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>0.445850</td>\n",
       "      <td>0.426313</td>\n",
       "      <td>0.430153</td>\n",
       "      <td>0.430153</td>\n",
       "      <td>0.469246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>0.428123</td>\n",
       "      <td>0.438253</td>\n",
       "      <td>0.421965</td>\n",
       "      <td>0.421965</td>\n",
       "      <td>0.430052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>0.392024</td>\n",
       "      <td>0.344428</td>\n",
       "      <td>0.295760</td>\n",
       "      <td>0.295760</td>\n",
       "      <td>0.441871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>0.229015</td>\n",
       "      <td>0.309816</td>\n",
       "      <td>0.442195</td>\n",
       "      <td>0.442195</td>\n",
       "      <td>0.205619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>0.401156</td>\n",
       "      <td>0.390929</td>\n",
       "      <td>0.424468</td>\n",
       "      <td>0.424468</td>\n",
       "      <td>0.425276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>0.322479</td>\n",
       "      <td>0.349493</td>\n",
       "      <td>0.442196</td>\n",
       "      <td>0.442196</td>\n",
       "      <td>0.248191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>0.333092</td>\n",
       "      <td>0.348528</td>\n",
       "      <td>0.262524</td>\n",
       "      <td>0.262524</td>\n",
       "      <td>0.360106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>0.227448</td>\n",
       "      <td>0.235166</td>\n",
       "      <td>0.360308</td>\n",
       "      <td>0.360308</td>\n",
       "      <td>0.143029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>0.123734</td>\n",
       "      <td>0.228413</td>\n",
       "      <td>0.422446</td>\n",
       "      <td>0.422446</td>\n",
       "      <td>0.024361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>0.176923</td>\n",
       "      <td>0.325645</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.025896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "a1                    0.015678  0.034491  0.072254       0.072254  0.000724\n",
       "mother_education      0.147250  0.132537  0.337668       0.337668  0.306198\n",
       "father_education      0.073444  0.199831  0.368014       0.368014  0.161480\n",
       "mother_occupation     0.418354  0.409912  0.377166       0.377166  0.458392\n",
       "father_occupation     0.445850  0.426313  0.430153       0.430153  0.469246\n",
       "inmigrant_second_gen  0.428123  0.438253  0.421965       0.421965  0.430052\n",
       "start_schooling_age   0.392024  0.344428  0.295760       0.295760  0.441871\n",
       "books                 0.229015  0.309816  0.442195       0.442195  0.205619\n",
       "f12a                  0.401156  0.390929  0.424468       0.424468  0.425276\n",
       "public_private        0.322479  0.349493  0.442196       0.442196  0.248191\n",
       "capital_island        0.333092  0.348528  0.262524       0.262524  0.360106\n",
       "d14                   0.227448  0.235166  0.360308       0.360308  0.143029\n",
       "ESCS_median           0.123734  0.228413  0.422446       0.422446  0.024361\n",
       "ESCS_p25_p75          0.176923  0.325645  0.494900       0.494900  0.025896"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_below_25 = run_experiments(data=data, percentile=\"below-25\", ineq_index=\"gini\")\n",
    "df_below_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between 25th and 75th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.006274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>0.289454</td>\n",
       "      <td>0.304778</td>\n",
       "      <td>0.349734</td>\n",
       "      <td>0.349734</td>\n",
       "      <td>0.273407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>0.146959</td>\n",
       "      <td>0.158542</td>\n",
       "      <td>0.212448</td>\n",
       "      <td>0.212448</td>\n",
       "      <td>0.130188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>0.465854</td>\n",
       "      <td>0.468870</td>\n",
       "      <td>0.532660</td>\n",
       "      <td>0.532660</td>\n",
       "      <td>0.457770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>0.471404</td>\n",
       "      <td>0.480212</td>\n",
       "      <td>0.508874</td>\n",
       "      <td>0.508874</td>\n",
       "      <td>0.462958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>0.430502</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.423207</td>\n",
       "      <td>0.423207</td>\n",
       "      <td>0.431708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>0.427927</td>\n",
       "      <td>0.434362</td>\n",
       "      <td>0.443693</td>\n",
       "      <td>0.443693</td>\n",
       "      <td>0.421171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>0.213923</td>\n",
       "      <td>0.241192</td>\n",
       "      <td>0.359152</td>\n",
       "      <td>0.359152</td>\n",
       "      <td>0.200289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>0.419787</td>\n",
       "      <td>0.423648</td>\n",
       "      <td>0.420188</td>\n",
       "      <td>0.420188</td>\n",
       "      <td>0.414381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>0.236969</td>\n",
       "      <td>0.240106</td>\n",
       "      <td>0.283868</td>\n",
       "      <td>0.283868</td>\n",
       "      <td>0.242760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>0.365347</td>\n",
       "      <td>0.362210</td>\n",
       "      <td>0.369838</td>\n",
       "      <td>0.369838</td>\n",
       "      <td>0.364865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.143581</td>\n",
       "      <td>0.183651</td>\n",
       "      <td>0.183651</td>\n",
       "      <td>0.152992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>0.007963</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.008687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.005175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "a1                    0.001931  0.002413  0.003502       0.003502  0.006274\n",
       "mother_education      0.289454  0.304778  0.349734       0.349734  0.273407\n",
       "father_education      0.146959  0.158542  0.212448       0.212448  0.130188\n",
       "mother_occupation     0.465854  0.468870  0.532660       0.532660  0.457770\n",
       "father_occupation     0.471404  0.480212  0.508874       0.508874  0.462958\n",
       "inmigrant_second_gen  0.430502  0.428571  0.423207       0.423207  0.431708\n",
       "start_schooling_age   0.427927  0.434362  0.443693       0.443693  0.421171\n",
       "books                 0.213923  0.241192  0.359152       0.359152  0.200289\n",
       "f12a                  0.419787  0.423648  0.420188       0.420188  0.414381\n",
       "public_private        0.236969  0.240106  0.283868       0.283868  0.242760\n",
       "capital_island        0.365347  0.362210  0.369838       0.369838  0.364865\n",
       "d14                   0.141892  0.143581  0.183651       0.183651  0.152992\n",
       "ESCS_median           0.007963  0.011824  0.004226       0.004226  0.008687\n",
       "ESCS_p25_p75          0.002004  0.012182  0.001460       0.001460  0.005175"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_between_25_75 = run_experiments(data=data, percentile=\"between-25-75\", ineq_index=\"gini\")\n",
    "df_between_25_75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above 75th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.042692</td>\n",
       "      <td>0.078389</td>\n",
       "      <td>0.078389</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_education</th>\n",
       "      <td>0.429690</td>\n",
       "      <td>0.510249</td>\n",
       "      <td>0.711165</td>\n",
       "      <td>0.711165</td>\n",
       "      <td>0.295585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_education</th>\n",
       "      <td>0.289555</td>\n",
       "      <td>0.423419</td>\n",
       "      <td>0.654243</td>\n",
       "      <td>0.654243</td>\n",
       "      <td>0.154486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_occupation</th>\n",
       "      <td>0.475517</td>\n",
       "      <td>0.493124</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>0.451639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father_occupation</th>\n",
       "      <td>0.471417</td>\n",
       "      <td>0.473346</td>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.464904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inmigrant_second_gen</th>\n",
       "      <td>0.437288</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.458031</td>\n",
       "      <td>0.458031</td>\n",
       "      <td>0.432947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_schooling_age</th>\n",
       "      <td>0.474673</td>\n",
       "      <td>0.509405</td>\n",
       "      <td>0.548318</td>\n",
       "      <td>0.548318</td>\n",
       "      <td>0.438333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>0.210202</td>\n",
       "      <td>0.263506</td>\n",
       "      <td>0.513144</td>\n",
       "      <td>0.513144</td>\n",
       "      <td>0.204172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12a</th>\n",
       "      <td>0.442256</td>\n",
       "      <td>0.457113</td>\n",
       "      <td>0.526385</td>\n",
       "      <td>0.526385</td>\n",
       "      <td>0.428942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_private</th>\n",
       "      <td>0.188856</td>\n",
       "      <td>0.155571</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.251567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_island</th>\n",
       "      <td>0.388084</td>\n",
       "      <td>0.378919</td>\n",
       "      <td>0.449830</td>\n",
       "      <td>0.449830</td>\n",
       "      <td>0.362035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>0.085625</td>\n",
       "      <td>0.074530</td>\n",
       "      <td>0.130969</td>\n",
       "      <td>0.130969</td>\n",
       "      <td>0.147853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_median</th>\n",
       "      <td>0.109744</td>\n",
       "      <td>0.206705</td>\n",
       "      <td>0.433429</td>\n",
       "      <td>0.433429</td>\n",
       "      <td>0.005065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESCS_p25_p75</th>\n",
       "      <td>0.170280</td>\n",
       "      <td>0.299114</td>\n",
       "      <td>0.489999</td>\n",
       "      <td>0.489999</td>\n",
       "      <td>0.006306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "a1                    0.024843  0.042692  0.078389       0.078389  0.000241\n",
       "mother_education      0.429690  0.510249  0.711165       0.711165  0.295585\n",
       "father_education      0.289555  0.423419  0.654243       0.654243  0.154486\n",
       "mother_occupation     0.475517  0.493124  0.491918       0.491918  0.451639\n",
       "father_occupation     0.471417  0.473346  0.489989       0.489989  0.464904\n",
       "inmigrant_second_gen  0.437288  0.431017  0.458031       0.458031  0.432947\n",
       "start_schooling_age   0.474673  0.509405  0.548318       0.548318  0.438333\n",
       "books                 0.210202  0.263506  0.513144       0.513144  0.204172\n",
       "f12a                  0.442256  0.457113  0.526385       0.526385  0.428942\n",
       "public_private        0.188856  0.155571  0.024843       0.024843  0.251567\n",
       "capital_island        0.388084  0.378919  0.449830       0.449830  0.362035\n",
       "d14                   0.085625  0.074530  0.130969       0.130969  0.147853\n",
       "ESCS_median           0.109744  0.206705  0.433429       0.433429  0.005065\n",
       "ESCS_p25_p75          0.170280  0.299114  0.489999       0.489999  0.006306"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_above_75 = run_experiments(data=data, percentile=\"above-75\", ineq_index=\"gini\")\n",
    "df_above_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_means = np.concatenate([\n",
    "    df_below_25.mean(axis=0).to_numpy().reshape((1, df_below_25.shape[1])),\n",
    "    df_above_75.mean(axis=0).to_numpy().reshape((1, df_above_75.shape[1])),\n",
    "    df_between_25_75.mean(axis=0).to_numpy().reshape((1, df_between_25_75.shape[1]))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Circumstances</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>below_25</th>\n",
       "      <td>0.266755</td>\n",
       "      <td>0.298125</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.264317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>above_75</th>\n",
       "      <td>0.299859</td>\n",
       "      <td>0.337051</td>\n",
       "      <td>0.428618</td>\n",
       "      <td>0.428618</td>\n",
       "      <td>0.260291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between_25_75</th>\n",
       "      <td>0.258708</td>\n",
       "      <td>0.265178</td>\n",
       "      <td>0.292607</td>\n",
       "      <td>0.292607</td>\n",
       "      <td>0.255188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model 1   Model 2   Model 3  Circumstances    Effort\n",
       "below_25       0.266755  0.298125  0.368001       0.368001  0.264317\n",
       "above_75       0.299859  0.337051  0.428618       0.428618  0.260291\n",
       "between_25_75  0.258708  0.265178  0.292607       0.292607  0.255188"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means = pd.DataFrame(np_means, \n",
    "                        index=[\"below_25\", \"above_75\", \"between_25_75\"], \n",
    "                        columns=[\"Model 1\", \"Model 2\", \"Model 3\", \"Circumstances\", \"Effort\"])\n",
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
